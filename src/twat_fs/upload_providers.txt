# Folder Tree Structure

.
├── __init__.py
├── bashupload.py
├── catbox.py
├── core.py
├── dropbox.py
├── fal.py
├── litterbox.py
├── protocols.py
├── s3.py
├── simple.py
├── termbin.py
├── types.py
├── uguu.py
└── www0x0.py

1 directory, 14 files



# Folder: .

## File: __init__.py (Size: 1.84 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = []
# ///
# this_file: src/twat_fs/upload_providers/__init__.py

"""
Upload provider registry and base classes.
"""

from __future__ import annotations

import importlib
from typing import TYPE_CHECKING

from loguru import logger

from .core import RetryableError, NonRetryableError, UploadError
from .protocols import ProviderClient, Provider, ProviderHelp
from .types import ExpirationTime, UploadResult

if TYPE_CHECKING:
    from pathlib import Path

# List of available providers in order of preference
PROVIDERS_PREFERENCE = [
    "catbox",
    "litterbox",
    "dropbox",
    "s3",
    "fal",
    "bashupload",
    "termbin",
    "uguu",
    "www0x0",
    "simple",
]

__all__ = [
    "PROVIDERS_PREFERENCE",
    "ExpirationTime",
    "NonRetryableError",
    "Provider",
    "ProviderClient",
    "ProviderHelp",
    "RetryableError",
    "UploadError",
    "UploadResult",
    "get_provider_help",
    "get_provider_module",
]


def get_provider_module(provider: str) -> Provider | None:
    """
    Get the provider module for a given provider name.

    Args:
        provider: Name of the provider to get

    Returns:
        Optional[Provider]: Provider module if found and properly configured
    """
    try:
        module = importlib.import_module(f".{provider}", __package__)
        return module
    except ImportError as e:
        logger.debug(f"Failed to import provider {provider}: {e}")
        return None


def get_provider_help(provider: str) -> ProviderHelp | None:
    """
    Get help information for a provider.

    Args:
        provider: Name of the provider to get help for

    Returns:
        Optional[ProviderHelp]: Help information if provider exists
    """
    module = get_provider_module(provider)
    if module is None:
        return None
    return getattr(module, "PROVIDER_HELP", None)
```

## File: bashupload.py (Size: 3.52 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = ["aiohttp"]
# ///
# this_file: src/twat_fs/upload_providers/bashupload.py

"""
Bashupload.com upload provider.
A simple provider that uploads files to bashupload.com.
Files are automatically deleted after 3 days.
"""

import aiohttp
from pathlib import Path

from loguru import logger

from .simple import SimpleProviderBase, UploadResult
from . import ProviderHelp, ProviderClient

# Provider help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": "No setup required. Note: Files are deleted after 3 days.",
    "deps": "Python package: aiohttp",
}


class BashUploadProvider(SimpleProviderBase):
    """Provider for bashupload.com uploads"""

    def __init__(self) -> None:
        super().__init__()
        self.url = "https://bashupload.com"

    async def async_upload_file(
        self, file_path: Path, remote_path: str | Path | None = None
    ) -> UploadResult:
        """
        Upload file to bashupload.com

        Args:
            file_path: Path to the file to upload
            remote_path: Optional remote path (ignored as bashupload.com doesn't support custom paths)

        Returns:
            UploadResult containing the URL and status
        """
        try:
            async with aiohttp.ClientSession() as session:
                data = aiohttp.FormData()
                with self._open_file(file_path) as f:
                    data.add_field("file", f, filename=file_path.name)

                    async with session.post(self.url, data=data) as response:
                        if response.status != 200:
                            error = await response.text()
                            msg = (
                                f"Upload failed with status {response.status}: {error}"
                            )
                            raise ValueError(msg)

                        text = await response.text()
                        # Extract URL from response text
                        for line in text.splitlines():
                            if line.startswith("wget "):
                                url = line.split(" ")[1].strip()
                                logger.info(
                                    f"Successfully uploaded to bashupload: {url}"
                                )
                                return UploadResult(
                                    url=url, success=True, raw_response=text
                                )

                        msg = f"Could not find URL in response: {text}"
                        raise ValueError(msg)

        except Exception as e:
            logger.error(f"Failed to upload to bashupload: {e}")
            return UploadResult(url="", success=False, error=str(e))


# Module-level functions to implement the Provider protocol
def get_credentials() -> None:
    """Simple providers don't need credentials"""
    return None


def get_provider() -> ProviderClient | None:
    """Return an instance of the provider"""
    return BashUploadProvider()


def upload_file(local_path: str | Path, remote_path: str | Path | None = None) -> str:
    """
    Upload a file and return its URL.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path (ignored for simple providers)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails
    """
    provider = get_provider()
    if not provider:
        msg = "Failed to initialize provider"
        raise ValueError(msg)
    return provider.upload_file(local_path, remote_path)
```

## File: catbox.py (Size: 9.09 KB)

```
#!/usr/bin/env python3
# this_file: src/twat_fs/upload_providers/catbox.py

"""
Catbox.moe file upload provider.
Supports both anonymous and authenticated uploads, as well as URL-based uploads.
API documentation: https://catbox.moe/tools.php
"""

import os
from pathlib import Path
from typing import TypedDict
import aiohttp
from loguru import logger

from . import ProviderClient, UploadResult
from .core import (
    with_async_retry,
    with_retry,
    validate_file,
    async_to_sync,
    with_url_validation,
    RetryableError,
    NonRetryableError,
)

CATBOX_API_URL = "https://catbox.moe/user/api.php"


class CatboxCredentials(TypedDict, total=False):
    """Credentials for Catbox provider."""

    userhash: str | None


class CatboxProvider(ProviderClient):
    """Provider for catbox.moe file uploads."""

    def __init__(self, credentials: CatboxCredentials | None = None) -> None:
        """Initialize the Catbox provider with optional credentials."""
        self.credentials = credentials or {}
        self.userhash = self.credentials.get("userhash")

    @with_url_validation
    @with_async_retry(
        max_attempts=3,
        exceptions=(aiohttp.ClientError, RetryableError),
    )
    async def async_upload_file(
        self,
        file_path: Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
    ) -> UploadResult:
        """
        Upload a file to catbox.moe.

        Args:
            file_path: Local path to the file
            remote_path: Ignored for Catbox
            unique: If True, ensures unique filename (not supported by Catbox)
            force: If True, overwrites existing file (not supported by Catbox)
            upload_path: Custom upload path (not supported by Catbox)

        Returns:
            UploadResult with the public URL

        Raises:
            FileNotFoundError: If the file doesn't exist
            RetryableError: For temporary failures that can be retried
            NonRetryableError: For permanent failures
        """
        if not file_path.exists():
            msg = f"File not found: {file_path}"
            raise FileNotFoundError(msg)

        data = aiohttp.FormData()
        data.add_field("reqtype", "fileupload")

        # Add userhash if authenticated
        if self.userhash:
            data.add_field("userhash", self.userhash)

        # Add the file
        with open(file_path, "rb") as f:
            data.add_field(
                "fileToUpload",
                f,
                filename=file_path.name,
                content_type="application/octet-stream",
            )

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(CATBOX_API_URL, data=data) as response:
                    if response.status != 200:
                        msg = f"Upload failed with status {response.status}"
                        raise RetryableError(msg, "catbox")

                    url = await response.text()
                    if not url.startswith("http"):
                        msg = f"Invalid response from server: {url}"
                        raise NonRetryableError(msg, "catbox")

                    return UploadResult(
                        url=url,
                        metadata={
                            "provider": "catbox",
                            "userhash": self.userhash is not None,
                        },
                    )

            except aiohttp.ClientError as e:
                msg = f"Upload failed: {e}"
                raise RetryableError(msg, "catbox") from e

    @with_url_validation
    @with_async_retry(
        max_attempts=3,
        exceptions=(aiohttp.ClientError, RetryableError),
    )
    async def async_upload_url(
        self,
        url: str,
        *,
        unique: bool = False,
        force: bool = False,
    ) -> UploadResult:
        """
        Upload a file from a URL to catbox.moe.

        Args:
            url: The URL to upload from
            unique: If True, ensures unique filename (not supported by Catbox)
            force: If True, overwrites existing file (not supported by Catbox)

        Returns:
            UploadResult with the public URL

        Raises:
            RetryableError: For temporary failures that can be retried
            NonRetryableError: For permanent failures
        """
        data = aiohttp.FormData()
        data.add_field("reqtype", "urlupload")
        data.add_field("url", url)

        if self.userhash:
            data.add_field("userhash", self.userhash)

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(CATBOX_API_URL, data=data) as response:
                    if response.status != 200:
                        msg = f"Upload failed with status {response.status}"
                        raise RetryableError(msg, "catbox")

                    url = await response.text()
                    if not url.startswith("http"):
                        msg = f"Invalid response from server: {url}"
                        raise NonRetryableError(msg, "catbox")

                    return UploadResult(
                        url=url,
                        metadata={
                            "provider": "catbox",
                            "userhash": self.userhash is not None,
                        },
                    )

            except aiohttp.ClientError as e:
                msg = f"Upload failed: {e}"
                raise RetryableError(msg, "catbox") from e

    @with_async_retry(
        max_attempts=3,
        exceptions=(aiohttp.ClientError, RetryableError),
    )
    async def async_delete_files(self, files: list[str]) -> bool:
        """
        Delete files from catbox.moe (requires authentication).

        Args:
            files: List of filenames to delete (e.g., ["eh871k.png", "d9pove.gif"])

        Returns:
            True if deletion was successful

        Raises:
            NonRetryableError: If not authenticated or deletion fails
            RetryableError: If connection issues occur
        """
        if not self.userhash:
            msg = "Authentication required for file deletion"
            raise NonRetryableError(msg, "catbox")

        data = aiohttp.FormData()
        data.add_field("reqtype", "deletefiles")
        data.add_field("userhash", self.userhash)
        data.add_field("files", " ".join(files))

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(CATBOX_API_URL, data=data) as response:
                    if response.status == 429:  # Rate limit
                        error_text = await response.text()
                        msg = f"Rate limited: {error_text}"
                        raise RetryableError(msg, "catbox")
                    elif response.status != 200:
                        error_text = await response.text()
                        msg = f"File deletion failed: {error_text}"
                        raise NonRetryableError(msg, "catbox")
                    return True
            except aiohttp.ClientError as e:
                msg = f"Connection error: {e!s}"
                raise RetryableError(msg, "catbox") from e

    @validate_file
    @async_to_sync
    async def upload_file(
        self,
        local_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
    ) -> str:
        """
        Synchronously upload a file to catbox.moe.

        Args:
            local_path: Path to the local file
            remote_path: Ignored for Catbox
            unique: If True, ensures unique filename (not supported by Catbox)
            force: If True, overwrites existing file (not supported by Catbox)
            upload_path: Custom upload path (not supported by Catbox)

        Returns:
            The public URL of the uploaded file

        Raises:
            FileNotFoundError: If the file doesn't exist
            RetryableError: For temporary failures that can be retried
            NonRetryableError: For permanent failures
        """
        result = await self.async_upload_file(
            Path(local_path),
            remote_path,
            unique=unique,
            force=force,
            upload_path=upload_path,
        )
        return result.url


@with_retry(max_attempts=3)
def get_credentials() -> CatboxCredentials | None:
    """
    Get Catbox credentials from environment variables.

    Returns:
        Dict with credentials if CATBOX_USERHASH is set, None otherwise
    """
    userhash = os.getenv("CATBOX_USERHASH")
    return {"userhash": userhash} if userhash else None


@with_retry(max_attempts=3)
def get_provider() -> ProviderClient | None:
    """
    Initialize and return the Catbox provider.

    Returns:
        Configured CatboxProvider instance, or None if initialization fails
    """
    try:
        return CatboxProvider(get_credentials())
    except Exception as e:
        logger.error(f"Failed to initialize Catbox provider: {e}")
        return None
```

## File: core.py (Size: 10.17 KB)

```
#!/usr/bin/env python3
# this_file: src/twat_fs/upload_providers/core.py

"""
Core utilities and decorators for upload providers.
Provides common functionality for retrying uploads, handling errors, and managing async operations.
"""

import asyncio
import functools
import time
from enum import Enum
from pathlib import Path
from typing import TypeVar, ParamSpec, cast
from collections.abc import Callable, Awaitable
import aiohttp
from loguru import logger

# Type variables for generic decorators
T = TypeVar("T")
P = ParamSpec("P")

# Constants for URL validation
URL_CHECK_TIMEOUT = 30.0  # seconds
MAX_REDIRECTS = 5
USER_AGENT = "twat-fs/1.0"


class RetryStrategy(str, Enum):
    """Retry strategies for upload attempts."""

    EXPONENTIAL = "exponential"
    LINEAR = "linear"
    CONSTANT = "constant"


def with_retry(
    max_attempts: int = 3,
    initial_delay: float = 1.0,
    max_delay: float = 30.0,
    strategy: RetryStrategy = RetryStrategy.EXPONENTIAL,
    exceptions: tuple[type[Exception], ...] = (Exception,),
) -> Callable[[Callable[P, T]], Callable[P, T]]:
    """
    Decorator for retrying upload operations with configurable backoff.

    Args:
        max_attempts: Maximum number of retry attempts
        initial_delay: Initial delay between retries in seconds
        max_delay: Maximum delay between retries in seconds
        strategy: Retry strategy to use
        exceptions: Tuple of exceptions to catch and retry on

    Returns:
        Decorated function that implements retry logic
    """

    def decorator(func: Callable[P, T]) -> Callable[P, T]:
        @functools.wraps(func)
        def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
            last_exception = None
            delay = initial_delay

            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt == max_attempts - 1:
                        raise

                    # Calculate next delay based on strategy
                    if strategy == RetryStrategy.EXPONENTIAL:
                        delay = min(initial_delay * (2**attempt), max_delay)
                    elif strategy == RetryStrategy.LINEAR:
                        delay = min(initial_delay * (attempt + 1), max_delay)
                    else:  # CONSTANT
                        delay = initial_delay

                    logger.warning(
                        f"Attempt {attempt + 1}/{max_attempts} failed: {e}. "
                        f"Retrying in {delay:.1f}s..."
                    )
                    time.sleep(delay)

            assert last_exception is not None  # for type checker
            raise last_exception

        return wrapper

    return decorator


def with_async_retry(
    max_attempts: int = 3,
    initial_delay: float = 1.0,
    max_delay: float = 30.0,
    strategy: RetryStrategy = RetryStrategy.EXPONENTIAL,
    exceptions: tuple[type[Exception], ...] = (Exception,),
) -> Callable[[Callable[P, T]], Callable[P, T]]:
    """
    Decorator for retrying async upload operations with configurable backoff.
    Similar to with_retry but for async functions.
    """

    def decorator(func: Callable[P, T]) -> Callable[P, T]:
        @functools.wraps(func)
        async def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
            last_exception = None
            delay = initial_delay

            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt == max_attempts - 1:
                        raise

                    if strategy == RetryStrategy.EXPONENTIAL:
                        delay = min(initial_delay * (2**attempt), max_delay)
                    elif strategy == RetryStrategy.LINEAR:
                        delay = min(initial_delay * (attempt + 1), max_delay)
                    else:  # CONSTANT
                        delay = initial_delay

                    logger.warning(
                        f"Attempt {attempt + 1}/{max_attempts} failed: {e}. "
                        f"Retrying in {delay:.1f}s..."
                    )
                    await asyncio.sleep(delay)

            assert last_exception is not None  # for type checker
            raise last_exception

        return cast(Callable[P, T], wrapper)

    return decorator


def validate_file(func: Callable[P, T]) -> Callable[P, T]:
    """
    Decorator to validate file existence and permissions before upload.
    Common validation used by most providers.
    """

    @functools.wraps(func)
    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
        # Extract file path from args or kwargs
        file_path = next(
            (arg for arg in args if isinstance(arg, str | Path)),
            kwargs.get("local_path") or kwargs.get("file_path"),
        )

        if not file_path:
            msg = "No file path provided"
            raise ValueError(msg)

        path = Path(file_path)
        if not path.exists():
            msg = f"File not found: {path}"
            raise FileNotFoundError(msg)
        if not path.is_file():
            msg = f"Not a file: {path}"
            raise ValueError(msg)
        if not path.stat().st_size:
            msg = f"File is empty: {path}"
            raise ValueError(msg)
        if not path.stat().st_mode & 0o444:
            msg = f"File not readable: {path}"
            raise PermissionError(msg)

        return func(*args, **kwargs)

    return wrapper


def sync_to_async(func: Callable[P, T]) -> Callable[P, T]:
    """
    Decorator to convert a synchronous upload function to async.
    Useful for providers that need to implement both sync and async interfaces.
    """

    @functools.wraps(func)
    async def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
        return await asyncio.to_thread(func, *args, **kwargs)

    return cast(Callable[P, T], wrapper)


def async_to_sync(func: Callable[P, T]) -> Callable[P, T]:
    """
    Decorator to convert an async upload function to sync.
    Useful for providers that implement async upload but need to provide sync interface.
    """

    @functools.wraps(func)
    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
        return asyncio.run(func(*args, **kwargs))

    return wrapper


class UploadError(Exception):
    """Base exception for upload errors."""

    def __init__(self, message: str, provider: str | None = None) -> None:
        super().__init__(message)
        self.provider = provider


class RetryableError(UploadError):
    """Exception indicating the upload should be retried."""

    pass


class NonRetryableError(UploadError):
    """Exception indicating the upload should not be retried."""

    pass


async def validate_url(url: str, timeout: float = URL_CHECK_TIMEOUT) -> bool:
    """
    Validate that a URL is accessible by making a HEAD request.

    Args:
        url: The URL to validate
        timeout: Timeout in seconds for the request

    Returns:
        bool: True if URL is valid and accessible

    Raises:
        RetryableError: If the validation should be retried (e.g., timeout)
        NonRetryableError: If the URL is invalid or inaccessible
    """
    async with aiohttp.ClientSession() as session:
        try:
            # Configure client session with appropriate headers and settings
            headers = {
                "User-Agent": USER_AGENT,
                "Accept": "*/*",
            }

            async with session.head(
                url,
                headers=headers,
                timeout=timeout,
                allow_redirects=True,
                max_redirects=MAX_REDIRECTS,
            ) as response:
                # Check for various status codes
                if response.status == 200:
                    return True
                elif response.status in (
                    429,
                    503,
                    504,
                ):  # Rate limit or temporary server issues
                    msg = f"Server returned {response.status}"
                    raise RetryableError(msg, None)
                else:
                    msg = f"URL validation failed with status {response.status}"
                    raise NonRetryableError(msg, None)

        except aiohttp.ClientError as e:
            if isinstance(
                e,
                aiohttp.ServerTimeoutError
                | aiohttp.ServerDisconnectedError
                | aiohttp.ClientConnectorError,
            ):
                msg = f"Temporary connection error: {e}"
                raise RetryableError(msg, None) from e
            msg = f"URL validation failed: {e}"
            raise NonRetryableError(msg, None) from e


@with_async_retry(
    max_attempts=3,
    initial_delay=1.0,
    max_delay=10.0,
    strategy=RetryStrategy.EXPONENTIAL,
    exceptions=(RetryableError, aiohttp.ClientError),
)
async def ensure_url_accessible(url: str) -> str:
    """
    Verify that a URL is accessible with retries.

    Args:
        url: The URL to validate

    Returns:
        str: The validated URL

    Raises:
        NonRetryableError: If the URL is invalid or inaccessible after retries
    """
    if await validate_url(url):
        return url
    msg = f"URL {url} is not accessible"
    raise NonRetryableError(msg, None)


def with_url_validation(func: Callable[P, Awaitable[T]]) -> Callable[P, Awaitable[T]]:
    """
    Decorator to validate URLs returned by upload functions.
    Ensures the URL is accessible before returning it.

    Args:
        func: Async function that returns a URL or UploadResult

    Returns:
        Decorated function that validates the URL before returning
    """

    @functools.wraps(func)
    async def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
        result = await func(*args, **kwargs)

        # Handle both string URLs and UploadResult objects
        if isinstance(result, str):
            return cast(T, await ensure_url_accessible(result))
        elif hasattr(result, "url"):
            # For UploadResult objects
            result.url = await ensure_url_accessible(result.url)
            return result
        return result

    return wrapper
```

## File: dropbox.py (Size: 18.84 KB)

```
#!/usr/bin/env -S uv run
# /// script
# dependencies = [
#   "dropbox",
#   "python-dotenv",
#   "tenacity",
#   "loguru",
# ]
# ///
# this_file: src/twat_fs/upload_providers/dropbox.py

"""
Dropbox provider for file uploads.
This module provides functionality to upload files to Dropbox and get shareable links.
Supports optional force and unique upload modes, chunked uploads for large files, and custom upload paths.
"""

from __future__ import annotations

import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, TypedDict
from urllib import parse

import dropbox  # type: ignore
from dotenv import load_dotenv
from loguru import logger

# Provider-specific help messages
PROVIDER_HELP = {
    "setup": """To use Dropbox storage:
1. Create a Dropbox account if you don't have one
2. Go to https://www.dropbox.com/developers/apps
3. Create a new app or use an existing one
4. Generate an access token from the app console
5. Set the following environment variables:
   - DROPBOX_ACCESS_TOKEN: Your Dropbox access token
   Optional:
   - DROPBOX_REFRESH_TOKEN: OAuth2 refresh token
   - DROPBOX_APP_KEY: Dropbox app key
   - DROPBOX_APP_SECRET: Dropbox app secret""",
    "deps": """Additional setup needed:
1. Install the Dropbox SDK: pip install dropbox
2. If using OAuth2:
   - Set up your redirect URI in the app console
   - Implement the OAuth2 flow to get refresh tokens""",
}

load_dotenv()

# Constants
DEFAULT_UPLOAD_PATH = "/upload"
MAX_FILE_SIZE = 150 * 1024 * 1024  # 150MB
SMALL_FILE_THRESHOLD = 4 * 1024 * 1024  # 4MB threshold for chunked upload


class DropboxCredentials(TypedDict):
    """Type for Dropbox credentials and configuration."""

    access_token: str
    refresh_token: str | None
    app_key: str | None
    app_secret: str | None


class DropboxClient:
    """Wrapper around Dropbox client that implements our ProviderClient protocol."""

    def __init__(self, credentials: DropboxCredentials) -> None:
        """Initialize the Dropbox client."""
        self.credentials = credentials
        self.dbx = self._create_client()

    def _create_client(self) -> dropbox.Dropbox:
        """Create and return a Dropbox client instance."""
        return dropbox.Dropbox(
            oauth2_access_token=self.credentials["access_token"],
            oauth2_refresh_token=self.credentials["refresh_token"],
            app_key=self.credentials["app_key"],
        )

    def _refresh_token_if_needed(self) -> None:
        """Refresh the access token if needed and possible."""
        try:
            # Check current token
            self.dbx.users_get_current_account()
        except dropbox.exceptions.AuthError as e:
            if "expired_access_token" in str(e):
                logger.debug("Access token expired, attempting refresh")
                try:
                    self.dbx.refresh_access_token()
                except Exception as refresh_err:
                    logger.debug(f"Unable to refresh access token: {refresh_err}")
            else:
                logger.debug(f"Authentication error: {e}")

    def upload_file(
        self,
        file_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        force: bool = False,
        unique: bool = False,
        upload_path: str = DEFAULT_UPLOAD_PATH,
    ) -> str:
        """Upload a file to Dropbox and return its URL."""
        logger.debug(f"Starting upload process for {file_path}")

        path = Path(file_path)
        if not path.exists():
            msg = f"File {path} does not exist"
            raise FileNotFoundError(msg)

        if not os.access(path, os.R_OK):
            msg = f"File {path} cannot be read"
            raise PermissionError(msg)

        try:
            # Check and refresh token if needed
            self._refresh_token_if_needed()

            # Normalize paths
            upload_path = _normalize_path(upload_path)

            # Use original filename if no remote path specified
            remote_path = path.name if remote_path is None else str(remote_path)

            # Add timestamp for unique filenames
            if unique:
                timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
                name, ext = os.path.splitext(remote_path)
                remote_path = f"{name}_{timestamp}{ext}"

            # Construct full Dropbox path
            db_path = _normalize_path(os.path.join(upload_path, remote_path))
            logger.debug(f"Target Dropbox path: {db_path}")

            # Ensure upload directory exists
            _ensure_upload_directory(self.dbx, upload_path)

            # Check if file exists
            exists, remote_metadata = _check_file_exists(self.dbx, db_path)
            if exists and not force:
                msg = f"File already exists at {db_path}"
                raise DropboxFileExistsError(msg)

            # Upload file based on size
            file_size = os.path.getsize(path)
            if file_size <= SMALL_FILE_THRESHOLD:
                _upload_small_file(self.dbx, path, db_path)
            else:
                _upload_large_file(self.dbx, path, db_path, SMALL_FILE_THRESHOLD)

            # Get shareable URL
            url = _get_share_url(self.dbx, db_path)
            if not url:
                msg = "Failed to get share URL"
                raise DropboxUploadError(msg)

            logger.info(f"Successfully uploaded to Dropbox: {url}")
            return url

        except DropboxFileExistsError:
            raise
        except Exception as e:
            logger.error(f"Failed to upload to Dropbox: {e}")
            msg = f"Upload failed: {e}"
            raise DropboxUploadError(msg) from e


def get_credentials() -> DropboxCredentials | None:
    """Get Dropbox credentials from environment variables."""
    access_token = os.getenv("DROPBOX_ACCESS_TOKEN")
    if not access_token:
        logger.debug("DROPBOX_ACCESS_TOKEN environment variable not set")
        return None

    creds: DropboxCredentials = {
        "access_token": access_token,
        "refresh_token": os.getenv("DROPBOX_REFRESH_TOKEN"),
        "app_key": os.getenv("DROPBOX_APP_KEY"),
        "app_secret": os.getenv("DROPBOX_APP_SECRET"),
    }
    return creds


def get_provider() -> DropboxClient | None:
    """Initialize and return the Dropbox client."""
    try:
        creds = get_credentials()
        if not creds:
            logger.debug("Dropbox credentials not found")
            return None

        client = DropboxClient(creds)
        try:
            # Test the client
            client.dbx.users_get_current_account()
            logger.debug("Successfully initialized Dropbox client")
            return client
        except dropbox.exceptions.AuthError as e:
            logger.error(f"Dropbox authentication failed: {e}")
            if "expired_access_token" in str(e):
                msg = "Failed to initialize Dropbox client: expired_access_token"
            else:
                msg = f"Failed to initialize Dropbox client: {e}"
            raise DropboxUploadError(msg) from e
        except Exception as e:
            logger.error(f"Failed to initialize Dropbox client: {e}")
            msg = f"Failed to initialize Dropbox client: {e}"
            raise DropboxUploadError(msg) from e

    except Exception as e:
        logger.error(f"Failed to initialize Dropbox client: {e}")
        return None


def upload_file(
    file_path: str | Path,
    remote_path: str | Path | None = None,
    *,
    force: bool = False,
    unique: bool = False,
    upload_path: str = DEFAULT_UPLOAD_PATH,
) -> str:
    """
    Upload a file to Dropbox and return its URL.

    Args:
        file_path: Path to the file to upload
        remote_path: Optional remote path to use
        force: Whether to overwrite existing files
        unique: Whether to ensure unique filenames
        upload_path: Custom base upload path

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails or credentials are invalid
    """
    client = get_provider()
    if not client:
        help_info = PROVIDER_HELP["setup"]
        msg = f"Dropbox credentials not found. {help_info}"
        raise ValueError(msg)

    # Use the original filename if no remote path specified
    if remote_path is None:
        remote_path = Path(file_path).name

    try:
        return client.upload_file(
            file_path,
            remote_path,
            force=force,
            unique=unique,
            upload_path=upload_path,
        )
    except DropboxFileExistsError as e:
        # Provide a more helpful error message
        msg = (
            f"File already exists in Dropbox. Use --force to overwrite, "
            f"or use --unique to create a unique filename. Error: {e}"
        )
        raise ValueError(msg) from e
    except DropboxUploadError as e:
        if "expired_access_token" in str(e):
            msg = "Failed to initialize Dropbox client: expired_access_token"
        else:
            msg = f"Failed to initialize Dropbox client: {e}"
        raise ValueError(msg) from e
    except Exception as e:
        msg = f"Failed to upload file: {e}"
        raise ValueError(msg) from e


class DropboxUploadError(Exception):
    """Base class for Dropbox upload errors."""


class PathConflictError(DropboxUploadError):
    """Raised when a path conflict occurs in safe mode."""


class DropboxFileExistsError(Exception):
    """Raised when a file already exists in Dropbox."""

    def __init__(self, message: str, url: str | None = None):
        super().__init__(message)
        self.url = url


class FolderExistsError(PathConflictError):
    """Raised when a folder exists where a file should be uploaded."""


def _validate_file(local_path: Path) -> None:
    """
    Validate file exists and can be read.

    Args:
        local_path: Path to the file to validate

    Raises:
        FileNotFoundError: If file does not exist
        PermissionError: If file cannot be read
    """
    if not get_provider():
        msg = "DROPBOX_ACCESS_TOKEN environment variable must be set"
        raise ValueError(msg)

    if not local_path.exists():
        msg = f"File {local_path} does not exist"
        raise FileNotFoundError(msg)

    if not os.access(local_path, os.R_OK):
        msg = f"File {local_path} cannot be read"
        raise PermissionError(msg)


def _get_download_url(url: str) -> str | None:
    """
    Convert a Dropbox share URL to a direct download URL.
    Preserves existing query parameters and adds dl=1 for direct download.

    Args:
        url: The Dropbox share URL to convert

    Returns:
        str | None: Direct download URL if successful, None otherwise
    """
    try:
        parsed = parse.urlparse(url)
        # Get existing query parameters
        query = dict(parse.parse_qsl(parsed.query))
        # Add or update dl parameter
        query["dl"] = "1"
        # Reconstruct URL with updated query
        return parsed._replace(
            netloc="dl.dropboxusercontent.com", query=parse.urlencode(query)
        ).geturl()
    except Exception as e:
        logger.error(f"Failed to generate download URL: {e}")
        return None


def _get_share_url(dbx: dropbox.Dropbox, db_path: str) -> str:
    """Get a shareable link for the uploaded file."""
    from tenacity import retry, stop_after_attempt, wait_exponential

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
    )
    def get_url() -> str:
        try:
            shared_link = dbx.sharing_create_shared_link_with_settings(db_path)
            # Convert to direct download URL
            url = shared_link.url.replace("?dl=0", "?dl=1")
            logger.debug(f"Created share URL: {url}")
            return url
        except Exception as e:
            logger.error(f"Failed to create share URL: {e}")
            raise

    return get_url()


def _ensure_upload_directory(dbx: Any, upload_path: str) -> None:
    """
    Ensure the upload directory exists.

    Args:
        dbx: Dropbox client
        upload_path: Path to ensure exists

    Raises:
        DropboxUploadError: If directory cannot be created
    """
    import dropbox

    logger.debug(f"Ensuring upload directory exists: {upload_path}")

    try:
        # Try to create directory and ancestors
        try:
            logger.debug(f"Attempting to create directory: {upload_path}")
            dbx.files_create_folder_v2(upload_path)
            logger.debug(f"Successfully created directory: {upload_path}")
        except dropbox.exceptions.ApiError as e:
            # Handle folder already exists case
            if (
                isinstance(e.error, dropbox.files.CreateFolderError)
                and e.error.get_path().is_conflict()
            ):
                logger.debug(f"Directory already exists: {upload_path}")
                return
            # For other API errors, raise
            logger.error(f"Failed to create directory: {e}")
            raise
    except Exception as e:
        msg = f"Failed to create upload directory: {e}"
        raise DropboxUploadError(msg) from e


def _get_file_metadata(dbx: Any, db_path: str) -> dict | None:
    """
    Get metadata for a file in Dropbox.

    Args:
        dbx: Dropbox client instance
        db_path: Path to the file in Dropbox

    Returns:
        dict | None: File metadata including size if file exists, None otherwise
    """
    import dropbox

    try:
        metadata = dbx.files_get_metadata(db_path)
        return {
            "size": metadata.size,
            "path": metadata.path_display,
            "id": metadata.id,
        }
    except dropbox.exceptions.ApiError as e:
        if e.error.is_path() and e.error.get_path().is_not_found():
            return None
        raise


def _check_file_exists(dbx: Any, db_path: str) -> tuple[bool, dict | None]:
    """
    Check if a file exists in Dropbox and return its metadata.

    Args:
        dbx: Dropbox client instance
        db_path: Path to the file in Dropbox

    Returns:
        tuple[bool, dict | None]: (exists, metadata)
        - exists: True if file exists
        - metadata: File metadata if exists, None otherwise
    """
    try:
        if metadata := _get_file_metadata(dbx, db_path):
            return True, metadata
        return False, None
    except Exception as e:
        logger.warning(f"Error checking file existence: {e}")
        return False, None


def _upload_small_file(dbx: dropbox.Dropbox, file_path: Path, db_path: str) -> None:
    """Upload a small file to Dropbox."""
    logger.debug(f"Uploading small file: {file_path} -> {db_path}")
    try:
        with open(file_path, "rb") as f:
            dbx.files_upload(f.read(), db_path, mode=dropbox.files.WriteMode.overwrite)
        logger.debug(f"Successfully uploaded small file: {db_path}")
    except Exception as e:
        logger.error(f"Failed to upload small file: {e}")
        msg = f"Failed to upload file: {e}"
        raise DropboxUploadError(msg) from e


def _upload_large_file(
    dbx: dropbox.Dropbox, file_path: Path, db_path: str, chunk_size: int
) -> None:
    """Upload a large file to Dropbox using chunked upload."""
    logger.debug(f"Starting chunked upload: {file_path} -> {db_path}")
    file_size = os.path.getsize(file_path)
    try:
        with open(file_path, "rb") as f:
            upload_session_start_result = dbx.files_upload_session_start(
                f.read(chunk_size)
            )
            logger.debug("Upload session started")

            cursor = dropbox.files.UploadSessionCursor(
                session_id=upload_session_start_result.session_id,
                offset=f.tell(),
            )
            commit = dropbox.files.CommitInfo(
                path=db_path, mode=dropbox.files.WriteMode.overwrite
            )

            while f.tell() < file_size:
                if (file_size - f.tell()) <= chunk_size:
                    logger.debug("Uploading final chunk")
                    dbx.files_upload_session_finish(f.read(chunk_size), cursor, commit)
                else:
                    logger.debug(f"Uploading chunk at offset {cursor.offset}")
                    dbx.files_upload_session_append_v2(f.read(chunk_size), cursor)
                    cursor.offset = f.tell()

        logger.debug(f"Successfully uploaded large file: {db_path}")
    except Exception as e:
        logger.error(f"Failed to upload large file: {e}")
        msg = f"Failed to upload file: {e}"
        raise DropboxUploadError(msg) from e


def _normalize_path(path: str) -> str:
    """
    Normalize a path for Dropbox (use forward slashes, no leading slash).

    Args:
        path: Path to normalize

    Returns:
        str: Normalized path
    """
    # Convert backslashes to forward slashes
    normalized = path.replace("\\", "/")
    # Remove leading slash if present
    normalized = normalized.lstrip("/")
    # Add leading slash back (Dropbox paths must start with slash)
    return f"/{normalized}"


def _handle_api_error(e: Any, operation: str) -> None:
    """
    Handle Dropbox API errors with proper error messages and logging.

    Args:
        e: The API error
        operation: Description of the operation that failed

    Raises:
        DropboxUploadError: With appropriate error message
    """
    import dropbox

    if isinstance(e, dropbox.exceptions.AuthError):
        logger.error(f"Authentication error during {operation}: {e}")
        msg = "Authentication failed. Please check your access token or refresh your credentials."
        raise DropboxUploadError(msg) from e
    elif isinstance(e, dropbox.exceptions.ApiError):
        if e.error.is_path():
            path_error = e.error.get_path()
            if path_error.is_not_found():
                logger.error(f"Path not found during {operation}: {e}")
                msg = f"Path not found: {path_error}"
                raise DropboxUploadError(msg) from e
            elif path_error.is_not_file():
                logger.error(f"Not a file error during {operation}: {e}")
                msg = f"Not a file: {path_error}"
                raise DropboxUploadError(msg) from e
            elif path_error.is_conflict():
                logger.error(f"Path conflict during {operation}: {e}")
                msg = f"Path conflict: {path_error}"
                raise DropboxUploadError(msg) from e
        logger.error(f"API error during {operation}: {e}")
        msg = f"Dropbox API error: {e}"
        raise DropboxUploadError(msg) from e
    else:
        logger.error(f"Unexpected error during {operation}: {e}")
        msg = f"Unexpected error: {e}"
        raise DropboxUploadError(msg) from e


def _validate_credentials(credentials: DropboxCredentials) -> None:
    """Validate Dropbox credentials."""
    # ... existing code ...


def _get_client(credentials: DropboxCredentials) -> Any:
    """Get Dropbox client instance."""
    # ... existing code ...


def _refresh_token(credentials: DropboxCredentials) -> DropboxCredentials | None:
    """Attempt to refresh the access token."""
    # ... existing code ...
```

## File: fal.py (Size: 4.85 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = [
#   "fal-client",
#   "loguru",
# ]
# ///
# this_file: src/twat_fs/upload_providers/fal.py

"""
FAL provider for file uploads.
This module provides functionality to upload files to FAL's storage service.
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import ClassVar

import fal_client  # type: ignore
from loguru import logger  # type: ignore

from . import Provider, ProviderClient, ProviderHelp

# Provider-specific help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": """To use FAL storage:
1. Create a FAL account at https://fal.ai
2. Generate an API key from your account settings
3. Set the following environment variable:
   - FAL_KEY: Your FAL API key""",
    "deps": """Additional setup needed:
1. Install the FAL client: pip install fal-client
2. Ensure your API key has the necessary permissions""",
}


class FalProvider(Provider):
    """Provider for uploading files to FAL."""

    # Class variable for provider help
    PROVIDER_HELP: ClassVar[ProviderHelp] = PROVIDER_HELP

    def __init__(self, key: str) -> None:
        """Initialize the FAL provider with the given API key."""
        self.client = fal_client.SyncClient(key=key)

    @classmethod
    def get_credentials(cls) -> dict[str, str] | None:
        """
        Fetch FAL credentials from environment.

        Returns:
            dict[str, str] | None: Dictionary with FAL key if present, None otherwise
        """
        key = os.getenv("FAL_KEY")
        return {"key": key} if key else None

    @classmethod
    def get_provider(cls) -> ProviderClient | None:
        """
        Initialize and return the FAL provider if credentials are present.

        Returns:
            Optional[Provider]: FAL provider instance if credentials are present, None otherwise
        """
        creds = cls.get_credentials()
        if not creds:
            logger.debug("FAL_KEY not set in environment")
            return None

        try:
            # Create a provider instance with the key
            return cls(key=creds["key"])
        except Exception as err:
            logger.warning(f"Failed to initialize FAL provider: {err}")
            return None

    def upload_file(
        self,
        local_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
    ) -> str:
        """
        Upload a file using FAL.

        Args:
            local_path: Path to the file to upload
            remote_path: Optional remote path (ignored for FAL)
            unique: Whether to ensure unique filenames (ignored for FAL)
            force: Whether to overwrite existing files (ignored for FAL)
            upload_path: Base path for uploads (ignored for FAL)

        Returns:
            str: URL to the uploaded file

        Raises:
            ValueError: If upload fails
            FileNotFoundError: If the file doesn't exist
        """
        path = Path(local_path)
        if not path.exists():
            msg = f"File not found: {path}"
            raise FileNotFoundError(msg)
        if not path.is_file():
            msg = f"Not a file: {path}"
            raise ValueError(msg)

        try:
            # FAL client's upload_file only accepts a string path
            result = self.client.upload_file(str(path))
            if not result:
                msg = "FAL upload failed - no URL in response"
                raise ValueError(msg)
            return str(result)

        except TypeError as e:
            # Handle type errors from the FAL client
            msg = f"FAL upload failed - invalid argument: {e}"
            raise ValueError(msg) from e
        except Exception as e:
            msg = f"FAL upload failed: {e}"
            raise ValueError(msg) from e


# Module-level functions that delegate to the FalProvider class
def get_credentials() -> dict[str, str] | None:
    """
    Get FAL credentials from environment.
    Delegates to FalProvider.get_credentials().
    """
    return FalProvider.get_credentials()


def get_provider() -> ProviderClient | None:
    """
    Initialize and return the FAL provider if credentials are present.
    Delegates to FalProvider.get_provider().
    """
    return FalProvider.get_provider()


def upload_file(
    local_path: str | Path,
    remote_path: str | Path | None = None,
    *,
    unique: bool = False,
    force: bool = False,
    upload_path: str | None = None,
) -> str:
    """
    Upload a file using FAL.
    Delegates to FalProvider.upload_file().
    """
    provider = get_provider()
    if not provider:
        msg = "FAL provider not configured"
        raise ValueError(msg)
    return provider.upload_file(
        local_path,
        remote_path=remote_path,
        unique=unique,
        force=force,
        upload_path=upload_path,
    )
```

## File: litterbox.py (Size: 5.35 KB)

```
#!/usr/bin/env python3
# this_file: src/twat_fs/upload_providers/litterbox.py

"""
Litterbox.catbox.moe file upload provider.
Supports temporary file uploads with configurable expiration times.
API documentation: https://litterbox.catbox.moe/tools.php
"""

import os
from pathlib import Path
from typing import Any
import aiohttp
import asyncio
from loguru import logger

from .protocols import ProviderClient
from .types import ExpirationTime, UploadResult

LITTERBOX_API_URL = "https://litterbox.catbox.moe/resources/internals/api.php"


class LitterboxProvider(ProviderClient):
    """Provider for litterbox.catbox.moe temporary file uploads."""

    def __init__(
        self, default_expiration: ExpirationTime = ExpirationTime.HOURS_12
    ) -> None:
        """
        Initialize the Litterbox provider.

        Args:
            default_expiration: Default expiration time for uploads

        Raises:
            ValueError: If the expiration time is invalid
        """
        if not isinstance(default_expiration, ExpirationTime):
            msg = f"Invalid expiration time: {default_expiration}"
            raise ValueError(msg)
        self.default_expiration = default_expiration

    async def async_upload_file(
        self,
        file_path: Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
        expiration: ExpirationTime | None = None,
    ) -> UploadResult:
        """
        Upload a file to litterbox.catbox.moe.

        Args:
            file_path: Path to the file to upload
            remote_path: Ignored for this provider
            unique: Ignored for this provider
            force: Ignored for this provider
            upload_path: Ignored for this provider
            expiration: Optional expiration time, defaults to provider default

        Returns:
            UploadResult: Upload result with URL and metadata

        Raises:
            RuntimeError: If the upload fails
        """
        if not file_path.exists():
            msg = f"File not found: {file_path}"
            raise RuntimeError(msg)

        expiration = expiration or self.default_expiration
        data = aiohttp.FormData()
        data.add_field("reqtype", "fileupload")
        data.add_field("time", expiration.value)

        with open(file_path, "rb") as f:
            data.add_field("fileToUpload", f, filename=file_path.name)

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(LITTERBOX_API_URL, data=data) as response:
                    if response.status != 200:
                        msg = f"Upload failed with status {response.status}"
                        raise RuntimeError(msg)

                    url = await response.text()
                    if not url.startswith("http"):
                        msg = f"Invalid response from server: {url}"
                        raise RuntimeError(msg)

                    return UploadResult(
                        url=url,
                        metadata={
                            "expiration": expiration.value,
                            "provider": "litterbox",
                        },
                    )

            except aiohttp.ClientError as e:
                msg = f"Upload failed: {e}"
                raise RuntimeError(msg) from e

    def upload_file(
        self,
        local_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
        expiration: ExpirationTime | None = None,
    ) -> str:
        """
        Synchronously upload a file to litterbox.catbox.moe.

        Args:
            local_path: Path to the file to upload
            remote_path: Ignored for this provider
            unique: Ignored for this provider
            force: Ignored for this provider
            upload_path: Ignored for this provider
            expiration: Optional expiration time, defaults to provider default

        Returns:
            str: URL to the uploaded file

        Raises:
            RuntimeError: If the upload fails
        """
        if isinstance(local_path, str):
            local_path = Path(local_path)

        result = asyncio.run(
            self.async_upload_file(
                local_path,
                remote_path,
                unique=unique,
                force=force,
                upload_path=upload_path,
                expiration=expiration,
            )
        )
        return result.url


def get_credentials() -> dict[str, Any] | None:
    """
    Get litterbox credentials from environment.
    Currently no credentials are needed for litterbox.

    Returns:
        None: Litterbox doesn't require credentials
    """
    return None


def get_provider() -> ProviderClient | None:
    """
    Initialize and return the litterbox provider.

    Returns:
        ProviderClient: Configured litterbox provider
    """
    default_expiration = os.getenv("LITTERBOX_DEFAULT_EXPIRATION", "24h")
    try:
        expiration = ExpirationTime(default_expiration)
    except ValueError:
        logger.warning(
            f"Invalid expiration time {default_expiration}, using 24h default"
        )
        expiration = ExpirationTime.HOURS_24

    return LitterboxProvider(default_expiration=expiration)
```

## File: protocols.py (Size: 1.81 KB)

```
#!/usr/bin/env python3
# this_file: src/twat_fs/upload_providers/protocols.py

"""
Protocol definitions for upload providers.
"""

from typing import Any, ClassVar, Protocol, TypedDict, runtime_checkable
from pathlib import Path


class ProviderHelp(TypedDict):
    """Type for provider help messages."""

    setup: str
    deps: str


@runtime_checkable
class ProviderClient(Protocol):
    """Protocol defining the interface for upload providers."""

    def upload_file(
        self,
        local_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
    ) -> str:
        """Upload a file and return its public URL."""
        ...


@runtime_checkable
class Provider(Protocol):
    """Protocol defining what a provider module must implement."""

    PROVIDER_HELP: ClassVar[ProviderHelp]

    @classmethod
    def get_credentials(cls) -> Any | None:
        """
        Get provider credentials from environment.

        Returns:
            Optional[Any]: Provider-specific credentials or None if not configured
        """
        ...

    @classmethod
    def get_provider(cls) -> ProviderClient | None:
        """
        Initialize and return the provider client.

        Returns:
            Optional[ProviderClient]: Provider client if successful, None otherwise
        """
        ...

    def upload_file(
        self, local_path: str | Path, remote_path: str | Path | None = None
    ) -> str:
        """
        Upload a file using this provider.

        Args:
            local_path: Path to the file to upload
            remote_path: Optional remote path to use

        Returns:
            str: URL to the uploaded file

        Raises:
            ValueError: If upload fails
        """
        ...
```

## File: s3.py (Size: 5.20 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = [
#   "boto3",
#   "loguru",
# ]
# ///
# this_file: src/twat_fs/upload_providers/s3.py

"""
AWS S3 provider for file uploads.
This module provides functionality to upload files to Amazon S3 storage service.
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import Any

import boto3
from loguru import logger

# Provider-specific help messages
PROVIDER_HELP = {
    "setup": """To use AWS S3 storage:
1. Create an AWS account if you don't have one
2. Create an S3 bucket to store your files
3. Set up AWS credentials by either:
   - Creating an IAM user and setting AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
   - Using AWS CLI: run 'aws configure'
   - Setting up IAM roles if running on AWS infrastructure
4. Set the following environment variables:
   - AWS_S3_BUCKET: Name of your S3 bucket
   - AWS_DEFAULT_REGION: AWS region (e.g. us-east-1)
   Optional:
   - AWS_ENDPOINT_URL: Custom S3 endpoint
   - AWS_S3_PATH_STYLE: Set to 'true' for path-style endpoints
   - AWS_ROLE_ARN: ARN of role to assume""",
    "deps": """Additional setup needed:
1. Install the AWS SDK: pip install boto3
2. If using AWS CLI: pip install awscli
3. Configure AWS credentials using one of the methods above
4. Ensure your IAM user/role has necessary S3 permissions:
   - s3:PutObject
   - s3:GetObject
   - s3:ListBucket""",
}


def get_credentials() -> dict[str, Any] | None:
    """
    Retrieve AWS S3 credentials from environment variables.

    Returns:
        Optional[Dict[str, Any]]: Credentials dict or None if not configured
    """
    bucket = os.getenv("AWS_S3_BUCKET")
    if not bucket:
        logger.debug("Required AWS_S3_BUCKET environment variable not set")
        return None

    region = os.getenv("AWS_DEFAULT_REGION")
    path_style = os.getenv("AWS_S3_PATH_STYLE", "").lower() == "true"
    endpoint_url = os.getenv("AWS_ENDPOINT_URL")
    role_arn = os.getenv("AWS_ROLE_ARN")
    access_key_id = os.getenv("AWS_ACCESS_KEY_ID")
    secret_access_key = os.getenv("AWS_SECRET_ACCESS_KEY")
    session_token = os.getenv("AWS_SESSION_TOKEN")

    return {
        "bucket": bucket,
        "region": region,
        "path_style": path_style,
        "endpoint_url": endpoint_url,
        "role_arn": role_arn,
        "aws_access_key_id": access_key_id,
        "aws_secret_access_key": secret_access_key,
        "aws_session_token": session_token,
    }


def get_provider(creds: dict[str, Any] | None = None):
    """
    Initialize and return the S3 provider using the boto3 client.

    Args:
        creds: Optional credentials dict (if None, will fetch from environment)

    Returns:
        Optional[boto3.client]: Configured S3 client or None if initialization fails
    """
    if creds is None:
        creds = get_credentials()
    if not creds:
        return None

    client_kwargs = {}
    if creds.get("region"):
        client_kwargs["region_name"] = creds["region"]
    if creds.get("endpoint_url"):
        client_kwargs["endpoint_url"] = creds["endpoint_url"]
    if creds.get("path_style"):
        from boto3.session import Config

        client_kwargs["config"] = Config(s3={"addressing_style": "path"})

    try:
        client = boto3.client("s3", **client_kwargs)
        # Test the client by listing buckets
        try:
            client.list_buckets()
            return client
        except Exception as e:
            logger.warning(f"Failed to validate S3 client: {e}")
            return None
    except Exception as e:
        logger.warning(f"Failed to create S3 client: {e}")
        return None


def upload_file(
    local_path: str | Path,
    remote_path: str | Path | None = None,
    *,  # Force keyword arguments for boolean flags
    unique: bool = False,  # Ignored for S3
    force: bool = False,  # Ignored for S3
    upload_path: str | None = None,  # Ignored for S3
) -> str:
    """
    Upload a file to AWS S3, handling multipart uploads for large files.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path/key to use in S3
        unique: Whether to ensure unique filenames (ignored for S3)
        force: Whether to overwrite existing files (ignored for S3)
        upload_path: Custom base upload path (ignored for S3)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails or credentials are missing
    """
    local_path = Path(local_path)
    creds = get_credentials()
    if not creds:
        msg = "S3 credentials not configured"
        raise ValueError(msg)

    client = get_provider(creds)
    if client is None:
        msg = "Failed to initialize S3 client"
        raise ValueError(msg)

    key = str(remote_path or local_path.name)
    try:
        # Use upload_fileobj for all files
        with open(local_path, "rb") as f:
            client.upload_fileobj(f, creds["bucket"], key)

        # Return the URL to the uploaded file
        if creds.get("endpoint_url"):
            return f"{creds['endpoint_url']}/{creds['bucket']}/{key}"
        return f"https://s3.amazonaws.com/{creds['bucket']}/{key}"
    except Exception as e:
        logger.warning(f"S3 upload failed: {e}")
        msg = "S3 upload failed"
        raise ValueError(msg) from e
```

## File: simple.py (Size: 3.90 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = []
# ///
# this_file: src/twat_fs/upload_providers/simple.py

"""
Base implementation for simple file upload providers like termbin, 0x0.st etc.
These providers typically just upload a file and return a URL, without auth or complex configuration.
"""

from __future__ import annotations

import os
from abc import ABC, abstractmethod
from contextlib import contextmanager
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Protocol, runtime_checkable, BinaryIO, ClassVar
from collections.abc import Generator

from . import ProviderHelp, Provider, ProviderClient


@dataclass
class UploadResult:
    """Result of a file upload operation"""

    url: str
    success: bool
    error: str | None = None
    raw_response: Any = None


@runtime_checkable
class SimpleProviderClient(Protocol):
    """Protocol for simple upload providers that just take a file and return a URL"""

    async def upload_file(self, file_path: Path) -> UploadResult:
        """Upload a file and return the result

        Args:
            file_path: Path to the file to upload

        Returns:
            UploadResult containing the URL and status
        """
        ...


class SimpleProviderBase(ABC, Provider):
    """Base class for simple upload providers"""

    # Class variable for provider help
    PROVIDER_HELP: ClassVar[ProviderHelp] = {
        "setup": "No setup required",
        "deps": "No additional dependencies required",
    }

    @contextmanager
    def _open_file(self, file_path: Path) -> Generator[BinaryIO, None, None]:
        """Safely open and close a file"""
        file = None
        try:
            file = open(file_path, "rb")
            yield file
        finally:
            if file:
                file.close()

    def _validate_file(self, file_path: Path) -> None:
        """Validate that a file exists and is readable"""
        if not file_path.exists():
            msg = f"File not found: {file_path}"
            raise FileNotFoundError(msg)
        if not file_path.is_file():
            msg = f"Not a file: {file_path}"
            raise ValueError(msg)
        if not os.access(file_path, os.R_OK):
            msg = f"Cannot read file: {file_path}"
            raise PermissionError(msg)

    @classmethod
    def get_credentials(cls) -> None:
        """Simple providers don't need credentials"""
        return None

    @classmethod
    def get_provider(cls) -> ProviderClient | None:
        """Return an instance of this provider"""
        return cls()

    def upload_file(
        self, local_path: str | Path, remote_path: str | Path | None = None
    ) -> str:
        """
        Upload a file and return its URL.
        Implements the ProviderClient interface by wrapping the async upload_file method.

        Args:
            local_path: Path to the file to upload
            remote_path: Optional remote path to use (ignored for simple providers)

        Returns:
            str: URL to the uploaded file

        Raises:
            FileNotFoundError: If the file doesn't exist
            ValueError: If the path is not a file
            PermissionError: If the file can't be read
            RuntimeError: If the upload fails
        """
        path = Path(local_path)
        self._validate_file(path)

        with self._open_file(path) as file:
            result = self.upload_file_impl(file)
            if not result.success:
                msg = f"Upload failed: {result.error or 'Unknown error'}"
                raise RuntimeError(msg)
            return result.url

    @abstractmethod
    def upload_file_impl(self, file: BinaryIO) -> UploadResult:
        """
        Implement the actual file upload logic.
        This method should be implemented by concrete provider classes.

        Args:
            file: Open file handle to upload

        Returns:
            UploadResult containing the URL and status
        """
        ...
```

## File: termbin.py (Size: 2.99 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = []
# ///
# this_file: src/twat_fs/upload_providers/termbin.py

"""
Termbin upload provider.
A simple provider that uploads text files to termbin.com using netcat.
"""

import asyncio
from pathlib import Path

from loguru import logger

from .simple import SimpleProviderBase, UploadResult
from . import ProviderHelp, ProviderClient

# Provider help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": "No setup required. Note: Only works with text files.",
    "deps": "System package: netcat (nc)",
}


class TermbinProvider(SimpleProviderBase):
    """Provider for termbin.com uploads"""

    def __init__(self) -> None:
        super().__init__()
        self.host = "termbin.com"
        self.port = 9999

    async def async_upload_file(
        self, file_path: Path, remote_path: str | Path | None = None
    ) -> UploadResult:
        """
        Upload text file to termbin.com using netcat

        Args:
            file_path: Path to the file to upload
            remote_path: Optional remote path (ignored as termbin.com doesn't support custom paths)

        Returns:
            UploadResult containing the URL and status
        """
        try:
            # Read file content
            with self._open_file(file_path) as f:
                content = f.read()

            # Connect to termbin.com
            reader, writer = await asyncio.open_connection(self.host, self.port)

            # Send file content
            writer.write(content)
            await writer.drain()

            # Get response
            response = await reader.read()
            writer.close()
            await writer.wait_closed()

            # Parse URL from response
            url = response.decode().strip()
            if not url.startswith("http"):
                msg = f"Invalid response from termbin: {url}"
                raise ValueError(msg)

            logger.info(f"Successfully uploaded to termbin: {url}")
            return UploadResult(url=url, success=True, raw_response=url)

        except Exception as e:
            logger.error(f"Failed to upload to termbin: {e}")
            return UploadResult(url="", success=False, error=str(e))


# Module-level functions to implement the Provider protocol
def get_credentials() -> None:
    """Simple providers don't need credentials"""
    return None


def get_provider() -> ProviderClient | None:
    """Return an instance of the provider"""
    return TermbinProvider()


def upload_file(local_path: str | Path, remote_path: str | Path | None = None) -> str:
    """
    Upload a file and return its URL.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path (ignored for simple providers)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails
    """
    provider = get_provider()
    if not provider:
        msg = "Failed to initialize provider"
        raise ValueError(msg)
    return provider.upload_file(local_path, remote_path)
```

## File: types.py (Size: 0.73 KB)

```
#!/usr/bin/env python3
# this_file: src/twat_fs/upload_providers/types.py

"""
Common types used across upload providers.
"""

from enum import Enum
from typing import Any


class ExpirationTime(str, Enum):
    """Valid expiration times for Litterbox uploads."""

    HOUR_1 = "1h"
    HOURS_12 = "12h"
    HOURS_24 = "24h"
    HOURS_72 = "72h"


class UploadResult:
    """Result of an upload operation."""

    def __init__(self, url: str, metadata: dict[str, Any] | None = None) -> None:
        """
        Initialize an upload result.

        Args:
            url: The URL where the uploaded file can be accessed
            metadata: Optional metadata about the upload
        """
        self.url = url
        self.metadata = metadata or {}
```

## File: uguu.py (Size: 3.22 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = ["aiohttp"]
# ///
# this_file: src/twat_fs/upload_providers/uguu.py

"""
Uguu.se upload provider.
A simple provider that uploads files to uguu.se.
Files are automatically deleted after 48 hours.
"""

import aiohttp
from pathlib import Path

from loguru import logger

from .simple import SimpleProviderBase, UploadResult
from . import ProviderHelp, ProviderClient

# Provider help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": "No setup required. Note: Files are deleted after 48 hours.",
    "deps": "Python package: aiohttp",
}


class UguuProvider(SimpleProviderBase):
    """Provider for uguu.se uploads"""

    def __init__(self) -> None:
        super().__init__()
        self.url = "https://uguu.se/upload.php"

    async def async_upload_file(
        self, file_path: Path, remote_path: str | Path | None = None
    ) -> UploadResult:
        """
        Upload file to uguu.se

        Args:
            file_path: Path to the file to upload
            remote_path: Optional remote path (ignored as uguu.se doesn't support custom paths)

        Returns:
            UploadResult containing the URL and status
        """
        try:
            async with aiohttp.ClientSession() as session:
                data = aiohttp.FormData()
                with self._open_file(file_path) as f:
                    data.add_field("files[]", f, filename=file_path.name)

                    async with session.post(self.url, data=data) as response:
                        if response.status != 200:
                            error = await response.text()
                            msg = (
                                f"Upload failed with status {response.status}: {error}"
                            )
                            raise ValueError(msg)

                        result = await response.json()
                        if not result or "files" not in result:
                            msg = f"Invalid response from uguu.se: {result}"
                            raise ValueError(msg)

                        url = result["files"][0]["url"]
                        logger.info(f"Successfully uploaded to uguu.se: {url}")

                        return UploadResult(url=url, success=True, raw_response=result)

        except Exception as e:
            logger.error(f"Failed to upload to uguu.se: {e}")
            return UploadResult(url="", success=False, error=str(e))


# Module-level functions to implement the Provider protocol
def get_credentials() -> None:
    """Simple providers don't need credentials"""
    return None


def get_provider() -> ProviderClient | None:
    """Return an instance of the provider"""
    return UguuProvider()


def upload_file(local_path: str | Path, remote_path: str | Path | None = None) -> str:
    """
    Upload a file and return its URL.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path (ignored for simple providers)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails
    """
    provider = get_provider()
    if not provider:
        msg = "Failed to initialize provider"
        raise ValueError(msg)
    return provider.upload_file(local_path, remote_path)
```

## File: www0x0.py (Size: 2.95 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = ["aiohttp"]
# ///
# this_file: src/twat_fs/upload_providers/www0x0.py

"""
0x0.st upload provider.
A simple provider that uploads files to 0x0.st.
Files are hosted at www.0x0.st.
"""

import aiohttp
from pathlib import Path

from loguru import logger

from .simple import SimpleProviderBase, UploadResult
from . import ProviderHelp, ProviderClient

# Provider help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": "No setup required.",
    "deps": "Python package: aiohttp",
}


class ZeroXZeroProvider(SimpleProviderBase):
    """Provider for 0x0.st uploads (www.0x0.st)"""

    def __init__(self) -> None:
        super().__init__()
        self.url = "https://0x0.st"

    async def async_upload_file(
        self, file_path: Path, remote_path: str | Path | None = None
    ) -> UploadResult:
        """
        Upload file to 0x0.st (www.0x0.st)

        Args:
            file_path: Path to the file to upload
            remote_path: Optional remote path (ignored as 0x0.st doesn't support custom paths)

        Returns:
            UploadResult containing the URL and status
        """
        try:
            async with aiohttp.ClientSession() as session:
                data = aiohttp.FormData()
                with self._open_file(file_path) as f:
                    data.add_field("file", f, filename=file_path.name)

                    async with session.post(self.url, data=data) as response:
                        if response.status != 200:
                            error = await response.text()
                            msg = (
                                f"Upload failed with status {response.status}: {error}"
                            )
                            raise ValueError(msg)

                        url = (await response.text()).strip()
                        logger.info(f"Successfully uploaded to 0x0.st: {url}")

                        return UploadResult(url=url, success=True, raw_response=url)

        except Exception as e:
            logger.error(f"Failed to upload to 0x0.st: {e}")
            return UploadResult(url="", success=False, error=str(e))


# Module-level functions to implement the Provider protocol
def get_credentials() -> None:
    """Simple providers don't need credentials"""
    return None


def get_provider() -> ProviderClient | None:
    """Return an instance of the provider"""
    return ZeroXZeroProvider()


def upload_file(local_path: str | Path, remote_path: str | Path | None = None) -> str:
    """
    Upload a file and return its URL.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path (ignored for simple providers)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails
    """
    provider = get_provider()
    if not provider:
        msg = "Failed to initialize provider"
        raise ValueError(msg)
    return provider.upload_file(local_path, remote_path)
```

