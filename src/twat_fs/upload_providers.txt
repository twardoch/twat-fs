# Folder Tree Structure

.
├── __init__.py
├── bashupload.py
├── catbox.py
├── dropbox.py
├── fal.py
├── litterbox.py
├── s3.py
├── simple.py
├── termbin.py
├── uguu.py
└── www0x0.py

1 directory, 11 files



# Folder: .

## File: __init__.py (Size: 5.68 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = []
# ///
# this_file: src/twat_fs/upload_providers/__init__.py

"""
Upload provider registry and base classes.
"""

from __future__ import annotations

import importlib
from typing import (
    TYPE_CHECKING,
    Any,
    Literal,
    Protocol,
    TypedDict,
    runtime_checkable,
    ClassVar,
)

from loguru import logger

if TYPE_CHECKING:
    from pathlib import Path


@runtime_checkable
class ProviderClient(Protocol):
    """Protocol defining the interface for upload providers."""

    def upload_file(
        self,
        local_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
    ) -> str:
        """Upload a file and return its public URL."""
        ...


class UploadResult:
    """Result of an upload operation."""

    def __init__(self, url: str, metadata: dict[str, Any] | None = None) -> None:
        """Initialize upload result."""
        self.url = url
        self.metadata = metadata or {}


# Order of preference for providers when none specified
PROVIDERS_PREFERENCE = [
    "catbox",  # Anonymous uploads, permanent
    "litterbox",  # Anonymous uploads, temporary
    "dropbox",  # Authenticated, permanent
    "s3",  # Authenticated, permanent
    "fal",  # Authenticated, permanent
    "www0x0",  # Anonymous uploads, permanent
    "uguu",  # Anonymous uploads, temporary
    "bashupload",  # Anonymous uploads, permanent
    "termbin",  # Anonymous uploads, text-only
]

# Map of provider module names to their import paths
PROVIDER_MODULES = {
    "catbox": "twat_fs.upload_providers.catbox",
    "litterbox": "twat_fs.upload_providers.litterbox",
    "dropbox": "twat_fs.upload_providers.dropbox",
    "s3": "twat_fs.upload_providers.s3",
    "fal": "twat_fs.upload_providers.fal",
    "www0x0": "twat_fs.upload_providers.www0x0",
    "uguu": "twat_fs.upload_providers.uguu",
    "bashupload": "twat_fs.upload_providers.bashupload",
    "termbin": "twat_fs.upload_providers.termbin",
}

# Provider help messages
PROVIDER_HELP = {
    "catbox": """
Catbox.moe File Upload Provider

Configuration:
- Optional: Set CATBOX_USERHASH for authenticated uploads
- No configuration needed for anonymous uploads

Features:
- Anonymous uploads (default)
- Authenticated uploads with user hash
- URL-based uploads
- File deletion (authenticated only)
""",
    "litterbox": """
Litterbox.catbox.moe Temporary File Upload Provider

Configuration:
- Optional: Set LITTERBOX_DEFAULT_EXPIRATION to '1h', '12h', '24h', or '72h'
- Defaults to '24h' if not specified

Features:
- Anonymous uploads only
- Configurable expiration times
- Files automatically deleted after expiration
""",
    # ... existing help messages ...
}

# Create ProviderType from PROVIDERS_PREFERENCE to ensure they stay in sync
ProviderType = Literal[tuple(PROVIDERS_PREFERENCE)]  # type: ignore


class ProviderHelp(TypedDict):
    """Type for provider help messages."""

    setup: str
    deps: str


@runtime_checkable
class Provider(Protocol):
    """Protocol defining what a provider module must implement."""

    PROVIDER_HELP: ClassVar[ProviderHelp]

    @classmethod
    def get_credentials(cls) -> Any | None:
        """
        Get provider credentials from environment.

        Returns:
            Optional[Any]: Provider-specific credentials or None if not configured
        """
        ...

    @classmethod
    def get_provider(cls) -> ProviderClient | None:
        """
        Initialize and return the provider client.

        Returns:
            Optional[ProviderClient]: Provider client if successful, None otherwise
        """
        ...

    def upload_file(
        self, local_path: str | Path, remote_path: str | Path | None = None
    ) -> str:
        """
        Upload a file using this provider.

        Args:
            local_path: Path to the file to upload
            remote_path: Optional remote path to use

        Returns:
            str: URL to the uploaded file

        Raises:
            ValueError: If upload fails
        """
        ...


# Provider module cache
_provider_modules: dict[str, Provider] = {}


def get_provider_module(provider: str) -> Provider | None:
    """
    Get a provider module, loading it if necessary.
    Uses a cache to avoid repeated imports.

    Args:
        provider: Name of the provider to load

    Returns:
        The provider module or None if import fails

    Raises:
        KeyError: If the provider is not in PROVIDERS_PREFERENCE
    """
    logger.debug(f"Getting provider module: {provider}")
    if provider not in PROVIDERS_PREFERENCE:
        msg = f"Invalid provider: {provider}"
        logger.error(msg)
        raise KeyError(msg)

    if provider not in _provider_modules:
        try:
            logger.debug(f"Importing provider module: {provider}")
            module = importlib.import_module(f"twat_fs.upload_providers.{provider}")
            if isinstance(module, Provider):
                logger.debug(f"Successfully loaded provider module: {provider}")
                _provider_modules[provider] = module
            else:
                logger.warning(
                    f"Module {provider} does not implement the Provider protocol"
                )
                return None
        except ImportError as e:
            logger.debug(f"Failed to import provider {provider}: {e}")
            return None
    return _provider_modules[provider]


def get_provider_help(provider: str) -> ProviderHelp | None:
    """Get help messages for a specific provider."""
    module = get_provider_module(provider)
    if not module:
        return None
    return module.PROVIDER_HELP if hasattr(module, "PROVIDER_HELP") else None
```

## File: bashupload.py (Size: 3.52 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = ["aiohttp"]
# ///
# this_file: src/twat_fs/upload_providers/bashupload.py

"""
Bashupload.com upload provider.
A simple provider that uploads files to bashupload.com.
Files are automatically deleted after 3 days.
"""

import aiohttp
from pathlib import Path

from loguru import logger

from .simple import SimpleProviderBase, UploadResult
from . import ProviderHelp, ProviderClient

# Provider help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": "No setup required. Note: Files are deleted after 3 days.",
    "deps": "Python package: aiohttp",
}


class BashUploadProvider(SimpleProviderBase):
    """Provider for bashupload.com uploads"""

    def __init__(self) -> None:
        super().__init__()
        self.url = "https://bashupload.com"

    async def async_upload_file(
        self, file_path: Path, remote_path: str | Path | None = None
    ) -> UploadResult:
        """
        Upload file to bashupload.com

        Args:
            file_path: Path to the file to upload
            remote_path: Optional remote path (ignored as bashupload.com doesn't support custom paths)

        Returns:
            UploadResult containing the URL and status
        """
        try:
            async with aiohttp.ClientSession() as session:
                data = aiohttp.FormData()
                with self._open_file(file_path) as f:
                    data.add_field("file", f, filename=file_path.name)

                    async with session.post(self.url, data=data) as response:
                        if response.status != 200:
                            error = await response.text()
                            msg = (
                                f"Upload failed with status {response.status}: {error}"
                            )
                            raise ValueError(msg)

                        text = await response.text()
                        # Extract URL from response text
                        for line in text.splitlines():
                            if line.startswith("wget "):
                                url = line.split(" ")[1].strip()
                                logger.info(
                                    f"Successfully uploaded to bashupload: {url}"
                                )
                                return UploadResult(
                                    url=url, success=True, raw_response=text
                                )

                        msg = f"Could not find URL in response: {text}"
                        raise ValueError(msg)

        except Exception as e:
            logger.error(f"Failed to upload to bashupload: {e}")
            return UploadResult(url="", success=False, error=str(e))


# Module-level functions to implement the Provider protocol
def get_credentials() -> None:
    """Simple providers don't need credentials"""
    return None


def get_provider() -> ProviderClient | None:
    """Return an instance of the provider"""
    return BashUploadProvider()


def upload_file(local_path: str | Path, remote_path: str | Path | None = None) -> str:
    """
    Upload a file and return its URL.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path (ignored for simple providers)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails
    """
    provider = get_provider()
    if not provider:
        msg = "Failed to initialize provider"
        raise ValueError(msg)
    return provider.upload_file(local_path, remote_path)
```

## File: catbox.py (Size: 6.76 KB)

```
#!/usr/bin/env python3
# this_file: src/twat_fs/upload_providers/catbox.py

"""
Catbox.moe file upload provider.
Supports both anonymous and authenticated uploads, as well as URL-based uploads.
API documentation: https://catbox.moe/tools.php
"""

import os
from pathlib import Path
from typing import Any, TypedDict
import aiohttp
import asyncio
from loguru import logger

from . import ProviderClient, UploadResult

CATBOX_API_URL = "https://catbox.moe/user/api.php"


class CatboxCredentials(TypedDict, total=False):
    """Credentials for Catbox provider."""

    userhash: str | None


class CatboxProvider(ProviderClient):
    """Provider for catbox.moe file uploads."""

    def __init__(self, credentials: CatboxCredentials | None = None) -> None:
        """Initialize the Catbox provider with optional credentials."""
        self.credentials = credentials or {}
        self.userhash = self.credentials.get("userhash")

    async def async_upload_file(
        self,
        file_path: Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
    ) -> UploadResult:
        """
        Upload a file to catbox.moe.

        Args:
            file_path: Local path to the file
            remote_path: Ignored for Catbox
            unique: If True, ensures unique filename (not supported by Catbox)
            force: If True, overwrites existing file (not supported by Catbox)
            upload_path: Custom upload path (not supported by Catbox)

        Returns:
            UploadResult with the public URL
        """
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")

        data = aiohttp.FormData()
        data.add_field("reqtype", "fileupload")

        # Add userhash if authenticated
        if self.userhash:
            data.add_field("userhash", self.userhash)

        # Add the file
        data.add_field(
            "fileToUpload",
            open(file_path, "rb"),
            filename=file_path.name,
            content_type="application/octet-stream",
        )

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(CATBOX_API_URL, data=data) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise RuntimeError(f"Upload failed: {error_text}")

                    url = await response.text()
                    return UploadResult(url=url.strip())
            except aiohttp.ClientError as e:
                raise RuntimeError(f"Upload failed: {str(e)}") from e

    async def async_upload_url(
        self,
        url: str,
        *,
        unique: bool = False,
        force: bool = False,
    ) -> UploadResult:
        """
        Upload a file from a URL to catbox.moe.

        Args:
            url: The URL to upload from
            unique: If True, ensures unique filename (not supported by Catbox)
            force: If True, overwrites existing file (not supported by Catbox)

        Returns:
            UploadResult with the public URL
        """
        data = aiohttp.FormData()
        data.add_field("reqtype", "urlupload")
        data.add_field("url", url)

        # Add userhash if authenticated
        if self.userhash:
            data.add_field("userhash", self.userhash)

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(CATBOX_API_URL, data=data) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise RuntimeError(f"URL upload failed: {error_text}")

                    result_url = await response.text()
                    return UploadResult(url=result_url.strip())
            except aiohttp.ClientError as e:
                raise RuntimeError(f"URL upload failed: {str(e)}") from e

    async def async_delete_files(self, files: list[str]) -> bool:
        """
        Delete files from catbox.moe (requires authentication).

        Args:
            files: List of filenames to delete (e.g., ["eh871k.png", "d9pove.gif"])

        Returns:
            True if deletion was successful

        Raises:
            RuntimeError: If not authenticated or deletion fails
        """
        if not self.userhash:
            raise RuntimeError("Authentication required for file deletion")

        data = aiohttp.FormData()
        data.add_field("reqtype", "deletefiles")
        data.add_field("userhash", self.userhash)
        data.add_field("files", " ".join(files))

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(CATBOX_API_URL, data=data) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise RuntimeError(f"File deletion failed: {error_text}")
                    return True
            except aiohttp.ClientError as e:
                raise RuntimeError(f"File deletion failed: {str(e)}") from e

    def upload_file(
        self,
        local_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
    ) -> str:
        """
        Synchronously upload a file to catbox.moe.

        Args:
            local_path: Path to the local file
            remote_path: Ignored for Catbox
            unique: If True, ensures unique filename (not supported by Catbox)
            force: If True, overwrites existing file (not supported by Catbox)
            upload_path: Custom upload path (not supported by Catbox)

        Returns:
            The public URL of the uploaded file
        """
        local_path = Path(local_path)
        result = asyncio.run(
            self.async_upload_file(
                local_path,
                remote_path,
                unique=unique,
                force=force,
                upload_path=upload_path,
            )
        )
        return result.url


def get_credentials() -> dict[str, Any] | None:
    """
    Get Catbox credentials from environment variables.

    Returns:
        Dict with credentials if CATBOX_USERHASH is set, None otherwise
    """
    userhash = os.getenv("CATBOX_USERHASH")
    return {"userhash": userhash} if userhash else None


def get_provider() -> ProviderClient | None:
    """
    Initialize and return the Catbox provider.

    Returns:
        Configured CatboxProvider instance, or None if initialization fails
    """
    try:
        return CatboxProvider(get_credentials())
    except Exception as e:
        logger.error(f"Failed to initialize Catbox provider: {e}")
        return None
```

## File: dropbox.py (Size: 18.84 KB)

```
#!/usr/bin/env -S uv run
# /// script
# dependencies = [
#   "dropbox",
#   "python-dotenv",
#   "tenacity",
#   "loguru",
# ]
# ///
# this_file: src/twat_fs/upload_providers/dropbox.py

"""
Dropbox provider for file uploads.
This module provides functionality to upload files to Dropbox and get shareable links.
Supports optional force and unique upload modes, chunked uploads for large files, and custom upload paths.
"""

from __future__ import annotations

import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, TypedDict
from urllib import parse

import dropbox  # type: ignore
from dotenv import load_dotenv
from loguru import logger

# Provider-specific help messages
PROVIDER_HELP = {
    "setup": """To use Dropbox storage:
1. Create a Dropbox account if you don't have one
2. Go to https://www.dropbox.com/developers/apps
3. Create a new app or use an existing one
4. Generate an access token from the app console
5. Set the following environment variables:
   - DROPBOX_ACCESS_TOKEN: Your Dropbox access token
   Optional:
   - DROPBOX_REFRESH_TOKEN: OAuth2 refresh token
   - DROPBOX_APP_KEY: Dropbox app key
   - DROPBOX_APP_SECRET: Dropbox app secret""",
    "deps": """Additional setup needed:
1. Install the Dropbox SDK: pip install dropbox
2. If using OAuth2:
   - Set up your redirect URI in the app console
   - Implement the OAuth2 flow to get refresh tokens""",
}

load_dotenv()

# Constants
DEFAULT_UPLOAD_PATH = "/upload"
MAX_FILE_SIZE = 150 * 1024 * 1024  # 150MB
SMALL_FILE_THRESHOLD = 4 * 1024 * 1024  # 4MB threshold for chunked upload


class DropboxCredentials(TypedDict):
    """Type for Dropbox credentials and configuration."""

    access_token: str
    refresh_token: str | None
    app_key: str | None
    app_secret: str | None


class DropboxClient:
    """Wrapper around Dropbox client that implements our ProviderClient protocol."""

    def __init__(self, credentials: DropboxCredentials) -> None:
        """Initialize the Dropbox client."""
        self.credentials = credentials
        self.dbx = self._create_client()

    def _create_client(self) -> dropbox.Dropbox:
        """Create and return a Dropbox client instance."""
        return dropbox.Dropbox(
            oauth2_access_token=self.credentials["access_token"],
            oauth2_refresh_token=self.credentials["refresh_token"],
            app_key=self.credentials["app_key"],
        )

    def _refresh_token_if_needed(self) -> None:
        """Refresh the access token if needed and possible."""
        try:
            # Check current token
            self.dbx.users_get_current_account()
        except dropbox.exceptions.AuthError as e:
            if "expired_access_token" in str(e):
                logger.debug("Access token expired, attempting refresh")
                try:
                    self.dbx.refresh_access_token()
                except Exception as refresh_err:
                    logger.debug(f"Unable to refresh access token: {refresh_err}")
            else:
                logger.debug(f"Authentication error: {e}")

    def upload_file(
        self,
        file_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        force: bool = False,
        unique: bool = False,
        upload_path: str = DEFAULT_UPLOAD_PATH,
    ) -> str:
        """Upload a file to Dropbox and return its URL."""
        logger.debug(f"Starting upload process for {file_path}")

        path = Path(file_path)
        if not path.exists():
            msg = f"File {path} does not exist"
            raise FileNotFoundError(msg)

        if not os.access(path, os.R_OK):
            msg = f"File {path} cannot be read"
            raise PermissionError(msg)

        try:
            # Check and refresh token if needed
            self._refresh_token_if_needed()

            # Normalize paths
            upload_path = _normalize_path(upload_path)

            # Use original filename if no remote path specified
            remote_path = path.name if remote_path is None else str(remote_path)

            # Add timestamp for unique filenames
            if unique:
                timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
                name, ext = os.path.splitext(remote_path)
                remote_path = f"{name}_{timestamp}{ext}"

            # Construct full Dropbox path
            db_path = _normalize_path(os.path.join(upload_path, remote_path))
            logger.debug(f"Target Dropbox path: {db_path}")

            # Ensure upload directory exists
            _ensure_upload_directory(self.dbx, upload_path)

            # Check if file exists
            exists, remote_metadata = _check_file_exists(self.dbx, db_path)
            if exists and not force:
                msg = f"File already exists at {db_path}"
                raise DropboxFileExistsError(msg)

            # Upload file based on size
            file_size = os.path.getsize(path)
            if file_size <= SMALL_FILE_THRESHOLD:
                _upload_small_file(self.dbx, path, db_path)
            else:
                _upload_large_file(self.dbx, path, db_path, SMALL_FILE_THRESHOLD)

            # Get shareable URL
            url = _get_share_url(self.dbx, db_path)
            if not url:
                msg = "Failed to get share URL"
                raise DropboxUploadError(msg)

            logger.info(f"Successfully uploaded to Dropbox: {url}")
            return url

        except DropboxFileExistsError:
            raise
        except Exception as e:
            logger.error(f"Failed to upload to Dropbox: {e}")
            msg = f"Upload failed: {e}"
            raise DropboxUploadError(msg) from e


def get_credentials() -> DropboxCredentials | None:
    """Get Dropbox credentials from environment variables."""
    access_token = os.getenv("DROPBOX_ACCESS_TOKEN")
    if not access_token:
        logger.debug("DROPBOX_ACCESS_TOKEN environment variable not set")
        return None

    creds: DropboxCredentials = {
        "access_token": access_token,
        "refresh_token": os.getenv("DROPBOX_REFRESH_TOKEN"),
        "app_key": os.getenv("DROPBOX_APP_KEY"),
        "app_secret": os.getenv("DROPBOX_APP_SECRET"),
    }
    return creds


def get_provider() -> DropboxClient | None:
    """Initialize and return the Dropbox client."""
    try:
        creds = get_credentials()
        if not creds:
            logger.debug("Dropbox credentials not found")
            return None

        client = DropboxClient(creds)
        try:
            # Test the client
            client.dbx.users_get_current_account()
            logger.debug("Successfully initialized Dropbox client")
            return client
        except dropbox.exceptions.AuthError as e:
            logger.error(f"Dropbox authentication failed: {e}")
            if "expired_access_token" in str(e):
                msg = "Failed to initialize Dropbox client: expired_access_token"
            else:
                msg = f"Failed to initialize Dropbox client: {e}"
            raise DropboxUploadError(msg) from e
        except Exception as e:
            logger.error(f"Failed to initialize Dropbox client: {e}")
            msg = f"Failed to initialize Dropbox client: {e}"
            raise DropboxUploadError(msg) from e

    except Exception as e:
        logger.error(f"Failed to initialize Dropbox client: {e}")
        return None


def upload_file(
    file_path: str | Path,
    remote_path: str | Path | None = None,
    *,
    force: bool = False,
    unique: bool = False,
    upload_path: str = DEFAULT_UPLOAD_PATH,
) -> str:
    """
    Upload a file to Dropbox and return its URL.

    Args:
        file_path: Path to the file to upload
        remote_path: Optional remote path to use
        force: Whether to overwrite existing files
        unique: Whether to ensure unique filenames
        upload_path: Custom base upload path

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails or credentials are invalid
    """
    client = get_provider()
    if not client:
        help_info = PROVIDER_HELP["setup"]
        msg = f"Dropbox credentials not found. {help_info}"
        raise ValueError(msg)

    # Use the original filename if no remote path specified
    if remote_path is None:
        remote_path = Path(file_path).name

    try:
        return client.upload_file(
            file_path,
            remote_path,
            force=force,
            unique=unique,
            upload_path=upload_path,
        )
    except DropboxFileExistsError as e:
        # Provide a more helpful error message
        msg = (
            f"File already exists in Dropbox. Use --force to overwrite, "
            f"or use --unique to create a unique filename. Error: {e}"
        )
        raise ValueError(msg) from e
    except DropboxUploadError as e:
        if "expired_access_token" in str(e):
            msg = "Failed to initialize Dropbox client: expired_access_token"
        else:
            msg = f"Failed to initialize Dropbox client: {e}"
        raise ValueError(msg) from e
    except Exception as e:
        msg = f"Failed to upload file: {e}"
        raise ValueError(msg) from e


class DropboxUploadError(Exception):
    """Base class for Dropbox upload errors."""


class PathConflictError(DropboxUploadError):
    """Raised when a path conflict occurs in safe mode."""


class DropboxFileExistsError(Exception):
    """Raised when a file already exists in Dropbox."""

    def __init__(self, message: str, url: str | None = None):
        super().__init__(message)
        self.url = url


class FolderExistsError(PathConflictError):
    """Raised when a folder exists where a file should be uploaded."""


def _validate_file(local_path: Path) -> None:
    """
    Validate file exists and can be read.

    Args:
        local_path: Path to the file to validate

    Raises:
        FileNotFoundError: If file does not exist
        PermissionError: If file cannot be read
    """
    if not get_provider():
        msg = "DROPBOX_ACCESS_TOKEN environment variable must be set"
        raise ValueError(msg)

    if not local_path.exists():
        msg = f"File {local_path} does not exist"
        raise FileNotFoundError(msg)

    if not os.access(local_path, os.R_OK):
        msg = f"File {local_path} cannot be read"
        raise PermissionError(msg)


def _get_download_url(url: str) -> str | None:
    """
    Convert a Dropbox share URL to a direct download URL.
    Preserves existing query parameters and adds dl=1 for direct download.

    Args:
        url: The Dropbox share URL to convert

    Returns:
        str | None: Direct download URL if successful, None otherwise
    """
    try:
        parsed = parse.urlparse(url)
        # Get existing query parameters
        query = dict(parse.parse_qsl(parsed.query))
        # Add or update dl parameter
        query["dl"] = "1"
        # Reconstruct URL with updated query
        return parsed._replace(
            netloc="dl.dropboxusercontent.com", query=parse.urlencode(query)
        ).geturl()
    except Exception as e:
        logger.error(f"Failed to generate download URL: {e}")
        return None


def _get_share_url(dbx: dropbox.Dropbox, db_path: str) -> str:
    """Get a shareable link for the uploaded file."""
    from tenacity import retry, stop_after_attempt, wait_exponential

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
    )
    def get_url() -> str:
        try:
            shared_link = dbx.sharing_create_shared_link_with_settings(db_path)
            # Convert to direct download URL
            url = shared_link.url.replace("?dl=0", "?dl=1")
            logger.debug(f"Created share URL: {url}")
            return url
        except Exception as e:
            logger.error(f"Failed to create share URL: {e}")
            raise

    return get_url()


def _ensure_upload_directory(dbx: Any, upload_path: str) -> None:
    """
    Ensure the upload directory exists.

    Args:
        dbx: Dropbox client
        upload_path: Path to ensure exists

    Raises:
        DropboxUploadError: If directory cannot be created
    """
    import dropbox

    logger.debug(f"Ensuring upload directory exists: {upload_path}")

    try:
        # Try to create directory and ancestors
        try:
            logger.debug(f"Attempting to create directory: {upload_path}")
            dbx.files_create_folder_v2(upload_path)
            logger.debug(f"Successfully created directory: {upload_path}")
        except dropbox.exceptions.ApiError as e:
            # Handle folder already exists case
            if (
                isinstance(e.error, dropbox.files.CreateFolderError)
                and e.error.get_path().is_conflict()
            ):
                logger.debug(f"Directory already exists: {upload_path}")
                return
            # For other API errors, raise
            logger.error(f"Failed to create directory: {e}")
            raise
    except Exception as e:
        msg = f"Failed to create upload directory: {e}"
        raise DropboxUploadError(msg) from e


def _get_file_metadata(dbx: Any, db_path: str) -> dict | None:
    """
    Get metadata for a file in Dropbox.

    Args:
        dbx: Dropbox client instance
        db_path: Path to the file in Dropbox

    Returns:
        dict | None: File metadata including size if file exists, None otherwise
    """
    import dropbox

    try:
        metadata = dbx.files_get_metadata(db_path)
        return {
            "size": metadata.size,
            "path": metadata.path_display,
            "id": metadata.id,
        }
    except dropbox.exceptions.ApiError as e:
        if e.error.is_path() and e.error.get_path().is_not_found():
            return None
        raise


def _check_file_exists(dbx: Any, db_path: str) -> tuple[bool, dict | None]:
    """
    Check if a file exists in Dropbox and return its metadata.

    Args:
        dbx: Dropbox client instance
        db_path: Path to the file in Dropbox

    Returns:
        tuple[bool, dict | None]: (exists, metadata)
        - exists: True if file exists
        - metadata: File metadata if exists, None otherwise
    """
    try:
        if metadata := _get_file_metadata(dbx, db_path):
            return True, metadata
        return False, None
    except Exception as e:
        logger.warning(f"Error checking file existence: {e}")
        return False, None


def _upload_small_file(dbx: dropbox.Dropbox, file_path: Path, db_path: str) -> None:
    """Upload a small file to Dropbox."""
    logger.debug(f"Uploading small file: {file_path} -> {db_path}")
    try:
        with open(file_path, "rb") as f:
            dbx.files_upload(f.read(), db_path, mode=dropbox.files.WriteMode.overwrite)
        logger.debug(f"Successfully uploaded small file: {db_path}")
    except Exception as e:
        logger.error(f"Failed to upload small file: {e}")
        msg = f"Failed to upload file: {e}"
        raise DropboxUploadError(msg) from e


def _upload_large_file(
    dbx: dropbox.Dropbox, file_path: Path, db_path: str, chunk_size: int
) -> None:
    """Upload a large file to Dropbox using chunked upload."""
    logger.debug(f"Starting chunked upload: {file_path} -> {db_path}")
    file_size = os.path.getsize(file_path)
    try:
        with open(file_path, "rb") as f:
            upload_session_start_result = dbx.files_upload_session_start(
                f.read(chunk_size)
            )
            logger.debug("Upload session started")

            cursor = dropbox.files.UploadSessionCursor(
                session_id=upload_session_start_result.session_id,
                offset=f.tell(),
            )
            commit = dropbox.files.CommitInfo(
                path=db_path, mode=dropbox.files.WriteMode.overwrite
            )

            while f.tell() < file_size:
                if (file_size - f.tell()) <= chunk_size:
                    logger.debug("Uploading final chunk")
                    dbx.files_upload_session_finish(f.read(chunk_size), cursor, commit)
                else:
                    logger.debug(f"Uploading chunk at offset {cursor.offset}")
                    dbx.files_upload_session_append_v2(f.read(chunk_size), cursor)
                    cursor.offset = f.tell()

        logger.debug(f"Successfully uploaded large file: {db_path}")
    except Exception as e:
        logger.error(f"Failed to upload large file: {e}")
        msg = f"Failed to upload file: {e}"
        raise DropboxUploadError(msg) from e


def _normalize_path(path: str) -> str:
    """
    Normalize a path for Dropbox (use forward slashes, no leading slash).

    Args:
        path: Path to normalize

    Returns:
        str: Normalized path
    """
    # Convert backslashes to forward slashes
    normalized = path.replace("\\", "/")
    # Remove leading slash if present
    normalized = normalized.lstrip("/")
    # Add leading slash back (Dropbox paths must start with slash)
    return f"/{normalized}"


def _handle_api_error(e: Any, operation: str) -> None:
    """
    Handle Dropbox API errors with proper error messages and logging.

    Args:
        e: The API error
        operation: Description of the operation that failed

    Raises:
        DropboxUploadError: With appropriate error message
    """
    import dropbox

    if isinstance(e, dropbox.exceptions.AuthError):
        logger.error(f"Authentication error during {operation}: {e}")
        msg = "Authentication failed. Please check your access token or refresh your credentials."
        raise DropboxUploadError(msg) from e
    elif isinstance(e, dropbox.exceptions.ApiError):
        if e.error.is_path():
            path_error = e.error.get_path()
            if path_error.is_not_found():
                logger.error(f"Path not found during {operation}: {e}")
                msg = f"Path not found: {path_error}"
                raise DropboxUploadError(msg) from e
            elif path_error.is_not_file():
                logger.error(f"Not a file error during {operation}: {e}")
                msg = f"Not a file: {path_error}"
                raise DropboxUploadError(msg) from e
            elif path_error.is_conflict():
                logger.error(f"Path conflict during {operation}: {e}")
                msg = f"Path conflict: {path_error}"
                raise DropboxUploadError(msg) from e
        logger.error(f"API error during {operation}: {e}")
        msg = f"Dropbox API error: {e}"
        raise DropboxUploadError(msg) from e
    else:
        logger.error(f"Unexpected error during {operation}: {e}")
        msg = f"Unexpected error: {e}"
        raise DropboxUploadError(msg) from e


def _validate_credentials(credentials: DropboxCredentials) -> None:
    """Validate Dropbox credentials."""
    # ... existing code ...


def _get_client(credentials: DropboxCredentials) -> Any:
    """Get Dropbox client instance."""
    # ... existing code ...


def _refresh_token(credentials: DropboxCredentials) -> DropboxCredentials | None:
    """Attempt to refresh the access token."""
    # ... existing code ...
```

## File: fal.py (Size: 4.85 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = [
#   "fal-client",
#   "loguru",
# ]
# ///
# this_file: src/twat_fs/upload_providers/fal.py

"""
FAL provider for file uploads.
This module provides functionality to upload files to FAL's storage service.
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import ClassVar

import fal_client  # type: ignore
from loguru import logger  # type: ignore

from . import Provider, ProviderClient, ProviderHelp

# Provider-specific help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": """To use FAL storage:
1. Create a FAL account at https://fal.ai
2. Generate an API key from your account settings
3. Set the following environment variable:
   - FAL_KEY: Your FAL API key""",
    "deps": """Additional setup needed:
1. Install the FAL client: pip install fal-client
2. Ensure your API key has the necessary permissions""",
}


class FalProvider(Provider):
    """Provider for uploading files to FAL."""

    # Class variable for provider help
    PROVIDER_HELP: ClassVar[ProviderHelp] = PROVIDER_HELP

    def __init__(self, key: str) -> None:
        """Initialize the FAL provider with the given API key."""
        self.client = fal_client.SyncClient(key=key)

    @classmethod
    def get_credentials(cls) -> dict[str, str] | None:
        """
        Fetch FAL credentials from environment.

        Returns:
            dict[str, str] | None: Dictionary with FAL key if present, None otherwise
        """
        key = os.getenv("FAL_KEY")
        return {"key": key} if key else None

    @classmethod
    def get_provider(cls) -> ProviderClient | None:
        """
        Initialize and return the FAL provider if credentials are present.

        Returns:
            Optional[Provider]: FAL provider instance if credentials are present, None otherwise
        """
        creds = cls.get_credentials()
        if not creds:
            logger.debug("FAL_KEY not set in environment")
            return None

        try:
            # Create a provider instance with the key
            return cls(key=creds["key"])
        except Exception as err:
            logger.warning(f"Failed to initialize FAL provider: {err}")
            return None

    def upload_file(
        self,
        local_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
    ) -> str:
        """
        Upload a file using FAL.

        Args:
            local_path: Path to the file to upload
            remote_path: Optional remote path (ignored for FAL)
            unique: Whether to ensure unique filenames (ignored for FAL)
            force: Whether to overwrite existing files (ignored for FAL)
            upload_path: Base path for uploads (ignored for FAL)

        Returns:
            str: URL to the uploaded file

        Raises:
            ValueError: If upload fails
            FileNotFoundError: If the file doesn't exist
        """
        path = Path(local_path)
        if not path.exists():
            msg = f"File not found: {path}"
            raise FileNotFoundError(msg)
        if not path.is_file():
            msg = f"Not a file: {path}"
            raise ValueError(msg)

        try:
            # FAL client's upload_file only accepts a string path
            result = self.client.upload_file(str(path))
            if not result:
                msg = "FAL upload failed - no URL in response"
                raise ValueError(msg)
            return str(result)

        except TypeError as e:
            # Handle type errors from the FAL client
            msg = f"FAL upload failed - invalid argument: {e}"
            raise ValueError(msg) from e
        except Exception as e:
            msg = f"FAL upload failed: {e}"
            raise ValueError(msg) from e


# Module-level functions that delegate to the FalProvider class
def get_credentials() -> dict[str, str] | None:
    """
    Get FAL credentials from environment.
    Delegates to FalProvider.get_credentials().
    """
    return FalProvider.get_credentials()


def get_provider() -> ProviderClient | None:
    """
    Initialize and return the FAL provider if credentials are present.
    Delegates to FalProvider.get_provider().
    """
    return FalProvider.get_provider()


def upload_file(
    local_path: str | Path,
    remote_path: str | Path | None = None,
    *,
    unique: bool = False,
    force: bool = False,
    upload_path: str | None = None,
) -> str:
    """
    Upload a file using FAL.
    Delegates to FalProvider.upload_file().
    """
    provider = get_provider()
    if not provider:
        msg = "FAL provider not configured"
        raise ValueError(msg)
    return provider.upload_file(
        local_path,
        remote_path=remote_path,
        unique=unique,
        force=force,
        upload_path=upload_path,
    )
```

## File: litterbox.py (Size: 5.33 KB)

```
#!/usr/bin/env python3
# this_file: src/twat_fs/upload_providers/litterbox.py

"""
Litterbox.catbox.moe file upload provider.
Supports temporary file uploads with configurable expiration times.
API documentation: https://litterbox.catbox.moe/tools.php
"""

import os
from enum import Enum
from pathlib import Path
from typing import Any
import aiohttp
import asyncio
from loguru import logger

from . import ProviderClient, UploadResult

LITTERBOX_API_URL = "https://litterbox.catbox.moe/resources/internals/api.php"


class ExpirationTime(str, Enum):
    """Valid expiration times for Litterbox uploads."""

    HOUR_1 = "1h"
    HOURS_12 = "12h"
    HOURS_24 = "24h"
    HOURS_72 = "72h"


class LitterboxProvider(ProviderClient):
    """Provider for litterbox.catbox.moe temporary file uploads."""

    def __init__(
        self, default_expiration: ExpirationTime = ExpirationTime.HOURS_24
    ) -> None:
        """
        Initialize the Litterbox provider.

        Args:
            default_expiration: Default expiration time for uploads
        """
        self.default_expiration = default_expiration

    async def async_upload_file(
        self,
        file_path: Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
        expiration: ExpirationTime | None = None,
    ) -> UploadResult:
        """
        Upload a file to litterbox.catbox.moe with expiration.

        Args:
            file_path: Local path to the file
            remote_path: Ignored for Litterbox
            unique: If True, ensures unique filename (not supported by Litterbox)
            force: If True, overwrites existing file (not supported by Litterbox)
            upload_path: Custom upload path (not supported by Litterbox)
            expiration: Optional expiration time, defaults to instance default

        Returns:
            UploadResult with the public URL

        Raises:
            FileNotFoundError: If the file doesn't exist
            RuntimeError: If the upload fails
        """
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")

        expiration = expiration or self.default_expiration

        data = aiohttp.FormData()
        data.add_field("reqtype", "fileupload")
        data.add_field("time", expiration.value)

        # Add the file
        data.add_field(
            "fileToUpload",
            open(file_path, "rb"),
            filename=file_path.name,
            content_type="application/octet-stream",
        )

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(LITTERBOX_API_URL, data=data) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise RuntimeError(f"Upload failed: {error_text}")

                    url = await response.text()
                    return UploadResult(
                        url=url.strip(), metadata={"expiration": expiration.value}
                    )
            except aiohttp.ClientError as e:
                raise RuntimeError(f"Upload failed: {str(e)}") from e

    def upload_file(
        self,
        local_path: str | Path,
        remote_path: str | Path | None = None,
        *,
        unique: bool = False,
        force: bool = False,
        upload_path: str | None = None,
        expiration: ExpirationTime | None = None,
    ) -> str:
        """
        Synchronously upload a file to litterbox.catbox.moe.

        Args:
            local_path: Path to the local file
            remote_path: Ignored for Litterbox
            unique: If True, ensures unique filename (not supported by Litterbox)
            force: If True, overwrites existing file (not supported by Litterbox)
            upload_path: Custom upload path (not supported by Litterbox)
            expiration: Optional expiration time, defaults to instance default

        Returns:
            The public URL of the uploaded file
        """
        local_path = Path(local_path)
        result = asyncio.run(
            self.async_upload_file(
                local_path,
                remote_path,
                unique=unique,
                force=force,
                upload_path=upload_path,
                expiration=expiration,
            )
        )
        return result.url


def get_credentials() -> dict[str, Any] | None:
    """
    Get Litterbox credentials (none required).

    Returns:
        None as Litterbox doesn't require authentication
    """
    return None


def get_provider() -> ProviderClient | None:
    """
    Initialize and return the Litterbox provider.

    Returns:
        Configured LitterboxProvider instance, or None if initialization fails
    """
    try:
        # Get default expiration from environment or use 24h
        default_expiration = os.getenv("LITTERBOX_DEFAULT_EXPIRATION", "24h")
        try:
            expiration = ExpirationTime(default_expiration)
        except ValueError:
            logger.warning(f"Invalid expiration time '{default_expiration}', using 24h")
            expiration = ExpirationTime.HOURS_24

        return LitterboxProvider(default_expiration=expiration)
    except Exception as e:
        logger.error(f"Failed to initialize Litterbox provider: {e}")
        return None
```

## File: s3.py (Size: 5.20 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = [
#   "boto3",
#   "loguru",
# ]
# ///
# this_file: src/twat_fs/upload_providers/s3.py

"""
AWS S3 provider for file uploads.
This module provides functionality to upload files to Amazon S3 storage service.
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import Any

import boto3
from loguru import logger

# Provider-specific help messages
PROVIDER_HELP = {
    "setup": """To use AWS S3 storage:
1. Create an AWS account if you don't have one
2. Create an S3 bucket to store your files
3. Set up AWS credentials by either:
   - Creating an IAM user and setting AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
   - Using AWS CLI: run 'aws configure'
   - Setting up IAM roles if running on AWS infrastructure
4. Set the following environment variables:
   - AWS_S3_BUCKET: Name of your S3 bucket
   - AWS_DEFAULT_REGION: AWS region (e.g. us-east-1)
   Optional:
   - AWS_ENDPOINT_URL: Custom S3 endpoint
   - AWS_S3_PATH_STYLE: Set to 'true' for path-style endpoints
   - AWS_ROLE_ARN: ARN of role to assume""",
    "deps": """Additional setup needed:
1. Install the AWS SDK: pip install boto3
2. If using AWS CLI: pip install awscli
3. Configure AWS credentials using one of the methods above
4. Ensure your IAM user/role has necessary S3 permissions:
   - s3:PutObject
   - s3:GetObject
   - s3:ListBucket""",
}


def get_credentials() -> dict[str, Any] | None:
    """
    Retrieve AWS S3 credentials from environment variables.

    Returns:
        Optional[Dict[str, Any]]: Credentials dict or None if not configured
    """
    bucket = os.getenv("AWS_S3_BUCKET")
    if not bucket:
        logger.debug("Required AWS_S3_BUCKET environment variable not set")
        return None

    region = os.getenv("AWS_DEFAULT_REGION")
    path_style = os.getenv("AWS_S3_PATH_STYLE", "").lower() == "true"
    endpoint_url = os.getenv("AWS_ENDPOINT_URL")
    role_arn = os.getenv("AWS_ROLE_ARN")
    access_key_id = os.getenv("AWS_ACCESS_KEY_ID")
    secret_access_key = os.getenv("AWS_SECRET_ACCESS_KEY")
    session_token = os.getenv("AWS_SESSION_TOKEN")

    return {
        "bucket": bucket,
        "region": region,
        "path_style": path_style,
        "endpoint_url": endpoint_url,
        "role_arn": role_arn,
        "aws_access_key_id": access_key_id,
        "aws_secret_access_key": secret_access_key,
        "aws_session_token": session_token,
    }


def get_provider(creds: dict[str, Any] | None = None):
    """
    Initialize and return the S3 provider using the boto3 client.

    Args:
        creds: Optional credentials dict (if None, will fetch from environment)

    Returns:
        Optional[boto3.client]: Configured S3 client or None if initialization fails
    """
    if creds is None:
        creds = get_credentials()
    if not creds:
        return None

    client_kwargs = {}
    if creds.get("region"):
        client_kwargs["region_name"] = creds["region"]
    if creds.get("endpoint_url"):
        client_kwargs["endpoint_url"] = creds["endpoint_url"]
    if creds.get("path_style"):
        from boto3.session import Config

        client_kwargs["config"] = Config(s3={"addressing_style": "path"})

    try:
        client = boto3.client("s3", **client_kwargs)
        # Test the client by listing buckets
        try:
            client.list_buckets()
            return client
        except Exception as e:
            logger.warning(f"Failed to validate S3 client: {e}")
            return None
    except Exception as e:
        logger.warning(f"Failed to create S3 client: {e}")
        return None


def upload_file(
    local_path: str | Path,
    remote_path: str | Path | None = None,
    *,  # Force keyword arguments for boolean flags
    unique: bool = False,  # Ignored for S3
    force: bool = False,  # Ignored for S3
    upload_path: str | None = None,  # Ignored for S3
) -> str:
    """
    Upload a file to AWS S3, handling multipart uploads for large files.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path/key to use in S3
        unique: Whether to ensure unique filenames (ignored for S3)
        force: Whether to overwrite existing files (ignored for S3)
        upload_path: Custom base upload path (ignored for S3)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails or credentials are missing
    """
    local_path = Path(local_path)
    creds = get_credentials()
    if not creds:
        msg = "S3 credentials not configured"
        raise ValueError(msg)

    client = get_provider(creds)
    if client is None:
        msg = "Failed to initialize S3 client"
        raise ValueError(msg)

    key = str(remote_path or local_path.name)
    try:
        # Use upload_fileobj for all files
        with open(local_path, "rb") as f:
            client.upload_fileobj(f, creds["bucket"], key)

        # Return the URL to the uploaded file
        if creds.get("endpoint_url"):
            return f"{creds['endpoint_url']}/{creds['bucket']}/{key}"
        return f"https://s3.amazonaws.com/{creds['bucket']}/{key}"
    except Exception as e:
        logger.warning(f"S3 upload failed: {e}")
        msg = "S3 upload failed"
        raise ValueError(msg) from e
```

## File: simple.py (Size: 3.90 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = []
# ///
# this_file: src/twat_fs/upload_providers/simple.py

"""
Base implementation for simple file upload providers like termbin, 0x0.st etc.
These providers typically just upload a file and return a URL, without auth or complex configuration.
"""

from __future__ import annotations

import os
from abc import ABC, abstractmethod
from contextlib import contextmanager
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Protocol, runtime_checkable, BinaryIO, ClassVar
from collections.abc import Generator

from . import ProviderHelp, Provider, ProviderClient


@dataclass
class UploadResult:
    """Result of a file upload operation"""

    url: str
    success: bool
    error: str | None = None
    raw_response: Any = None


@runtime_checkable
class SimpleProviderClient(Protocol):
    """Protocol for simple upload providers that just take a file and return a URL"""

    async def upload_file(self, file_path: Path) -> UploadResult:
        """Upload a file and return the result

        Args:
            file_path: Path to the file to upload

        Returns:
            UploadResult containing the URL and status
        """
        ...


class SimpleProviderBase(ABC, Provider):
    """Base class for simple upload providers"""

    # Class variable for provider help
    PROVIDER_HELP: ClassVar[ProviderHelp] = {
        "setup": "No setup required",
        "deps": "No additional dependencies required",
    }

    @contextmanager
    def _open_file(self, file_path: Path) -> Generator[BinaryIO, None, None]:
        """Safely open and close a file"""
        file = None
        try:
            file = open(file_path, "rb")
            yield file
        finally:
            if file:
                file.close()

    def _validate_file(self, file_path: Path) -> None:
        """Validate that a file exists and is readable"""
        if not file_path.exists():
            msg = f"File not found: {file_path}"
            raise FileNotFoundError(msg)
        if not file_path.is_file():
            msg = f"Not a file: {file_path}"
            raise ValueError(msg)
        if not os.access(file_path, os.R_OK):
            msg = f"Cannot read file: {file_path}"
            raise PermissionError(msg)

    @classmethod
    def get_credentials(cls) -> None:
        """Simple providers don't need credentials"""
        return None

    @classmethod
    def get_provider(cls) -> ProviderClient | None:
        """Return an instance of this provider"""
        return cls()

    def upload_file(
        self, local_path: str | Path, remote_path: str | Path | None = None
    ) -> str:
        """
        Upload a file and return its URL.
        Implements the ProviderClient interface by wrapping the async upload_file method.

        Args:
            local_path: Path to the file to upload
            remote_path: Optional remote path to use (ignored for simple providers)

        Returns:
            str: URL to the uploaded file

        Raises:
            FileNotFoundError: If the file doesn't exist
            ValueError: If the path is not a file
            PermissionError: If the file can't be read
            RuntimeError: If the upload fails
        """
        path = Path(local_path)
        self._validate_file(path)

        with self._open_file(path) as file:
            result = self.upload_file_impl(file)
            if not result.success:
                msg = f"Upload failed: {result.error or 'Unknown error'}"
                raise RuntimeError(msg)
            return result.url

    @abstractmethod
    def upload_file_impl(self, file: BinaryIO) -> UploadResult:
        """
        Implement the actual file upload logic.
        This method should be implemented by concrete provider classes.

        Args:
            file: Open file handle to upload

        Returns:
            UploadResult containing the URL and status
        """
        ...
```

## File: termbin.py (Size: 2.99 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = []
# ///
# this_file: src/twat_fs/upload_providers/termbin.py

"""
Termbin upload provider.
A simple provider that uploads text files to termbin.com using netcat.
"""

import asyncio
from pathlib import Path

from loguru import logger

from .simple import SimpleProviderBase, UploadResult
from . import ProviderHelp, ProviderClient

# Provider help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": "No setup required. Note: Only works with text files.",
    "deps": "System package: netcat (nc)",
}


class TermbinProvider(SimpleProviderBase):
    """Provider for termbin.com uploads"""

    def __init__(self) -> None:
        super().__init__()
        self.host = "termbin.com"
        self.port = 9999

    async def async_upload_file(
        self, file_path: Path, remote_path: str | Path | None = None
    ) -> UploadResult:
        """
        Upload text file to termbin.com using netcat

        Args:
            file_path: Path to the file to upload
            remote_path: Optional remote path (ignored as termbin.com doesn't support custom paths)

        Returns:
            UploadResult containing the URL and status
        """
        try:
            # Read file content
            with self._open_file(file_path) as f:
                content = f.read()

            # Connect to termbin.com
            reader, writer = await asyncio.open_connection(self.host, self.port)

            # Send file content
            writer.write(content)
            await writer.drain()

            # Get response
            response = await reader.read()
            writer.close()
            await writer.wait_closed()

            # Parse URL from response
            url = response.decode().strip()
            if not url.startswith("http"):
                msg = f"Invalid response from termbin: {url}"
                raise ValueError(msg)

            logger.info(f"Successfully uploaded to termbin: {url}")
            return UploadResult(url=url, success=True, raw_response=url)

        except Exception as e:
            logger.error(f"Failed to upload to termbin: {e}")
            return UploadResult(url="", success=False, error=str(e))


# Module-level functions to implement the Provider protocol
def get_credentials() -> None:
    """Simple providers don't need credentials"""
    return None


def get_provider() -> ProviderClient | None:
    """Return an instance of the provider"""
    return TermbinProvider()


def upload_file(local_path: str | Path, remote_path: str | Path | None = None) -> str:
    """
    Upload a file and return its URL.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path (ignored for simple providers)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails
    """
    provider = get_provider()
    if not provider:
        msg = "Failed to initialize provider"
        raise ValueError(msg)
    return provider.upload_file(local_path, remote_path)
```

## File: uguu.py (Size: 3.22 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = ["aiohttp"]
# ///
# this_file: src/twat_fs/upload_providers/uguu.py

"""
Uguu.se upload provider.
A simple provider that uploads files to uguu.se.
Files are automatically deleted after 48 hours.
"""

import aiohttp
from pathlib import Path

from loguru import logger

from .simple import SimpleProviderBase, UploadResult
from . import ProviderHelp, ProviderClient

# Provider help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": "No setup required. Note: Files are deleted after 48 hours.",
    "deps": "Python package: aiohttp",
}


class UguuProvider(SimpleProviderBase):
    """Provider for uguu.se uploads"""

    def __init__(self) -> None:
        super().__init__()
        self.url = "https://uguu.se/upload.php"

    async def async_upload_file(
        self, file_path: Path, remote_path: str | Path | None = None
    ) -> UploadResult:
        """
        Upload file to uguu.se

        Args:
            file_path: Path to the file to upload
            remote_path: Optional remote path (ignored as uguu.se doesn't support custom paths)

        Returns:
            UploadResult containing the URL and status
        """
        try:
            async with aiohttp.ClientSession() as session:
                data = aiohttp.FormData()
                with self._open_file(file_path) as f:
                    data.add_field("files[]", f, filename=file_path.name)

                    async with session.post(self.url, data=data) as response:
                        if response.status != 200:
                            error = await response.text()
                            msg = (
                                f"Upload failed with status {response.status}: {error}"
                            )
                            raise ValueError(msg)

                        result = await response.json()
                        if not result or "files" not in result:
                            msg = f"Invalid response from uguu.se: {result}"
                            raise ValueError(msg)

                        url = result["files"][0]["url"]
                        logger.info(f"Successfully uploaded to uguu.se: {url}")

                        return UploadResult(url=url, success=True, raw_response=result)

        except Exception as e:
            logger.error(f"Failed to upload to uguu.se: {e}")
            return UploadResult(url="", success=False, error=str(e))


# Module-level functions to implement the Provider protocol
def get_credentials() -> None:
    """Simple providers don't need credentials"""
    return None


def get_provider() -> ProviderClient | None:
    """Return an instance of the provider"""
    return UguuProvider()


def upload_file(local_path: str | Path, remote_path: str | Path | None = None) -> str:
    """
    Upload a file and return its URL.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path (ignored for simple providers)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails
    """
    provider = get_provider()
    if not provider:
        msg = "Failed to initialize provider"
        raise ValueError(msg)
    return provider.upload_file(local_path, remote_path)
```

## File: www0x0.py (Size: 2.95 KB)

```
#!/usr/bin/env python
# /// script
# dependencies = ["aiohttp"]
# ///
# this_file: src/twat_fs/upload_providers/www0x0.py

"""
0x0.st upload provider.
A simple provider that uploads files to 0x0.st.
Files are hosted at www.0x0.st.
"""

import aiohttp
from pathlib import Path

from loguru import logger

from .simple import SimpleProviderBase, UploadResult
from . import ProviderHelp, ProviderClient

# Provider help messages
PROVIDER_HELP: ProviderHelp = {
    "setup": "No setup required.",
    "deps": "Python package: aiohttp",
}


class ZeroXZeroProvider(SimpleProviderBase):
    """Provider for 0x0.st uploads (www.0x0.st)"""

    def __init__(self) -> None:
        super().__init__()
        self.url = "https://0x0.st"

    async def async_upload_file(
        self, file_path: Path, remote_path: str | Path | None = None
    ) -> UploadResult:
        """
        Upload file to 0x0.st (www.0x0.st)

        Args:
            file_path: Path to the file to upload
            remote_path: Optional remote path (ignored as 0x0.st doesn't support custom paths)

        Returns:
            UploadResult containing the URL and status
        """
        try:
            async with aiohttp.ClientSession() as session:
                data = aiohttp.FormData()
                with self._open_file(file_path) as f:
                    data.add_field("file", f, filename=file_path.name)

                    async with session.post(self.url, data=data) as response:
                        if response.status != 200:
                            error = await response.text()
                            msg = (
                                f"Upload failed with status {response.status}: {error}"
                            )
                            raise ValueError(msg)

                        url = (await response.text()).strip()
                        logger.info(f"Successfully uploaded to 0x0.st: {url}")

                        return UploadResult(url=url, success=True, raw_response=url)

        except Exception as e:
            logger.error(f"Failed to upload to 0x0.st: {e}")
            return UploadResult(url="", success=False, error=str(e))


# Module-level functions to implement the Provider protocol
def get_credentials() -> None:
    """Simple providers don't need credentials"""
    return None


def get_provider() -> ProviderClient | None:
    """Return an instance of the provider"""
    return ZeroXZeroProvider()


def upload_file(local_path: str | Path, remote_path: str | Path | None = None) -> str:
    """
    Upload a file and return its URL.

    Args:
        local_path: Path to the file to upload
        remote_path: Optional remote path (ignored for simple providers)

    Returns:
        str: URL to the uploaded file

    Raises:
        ValueError: If upload fails
    """
    provider = get_provider()
    if not provider:
        msg = "Failed to initialize provider"
        raise ValueError(msg)
    return provider.upload_file(local_path, remote_path)
```

