# this_file: twat_fs/pyproject.toml

# this_file: pyproject.toml

# Project Metadata Configuration
# ------------------------------
# Comprehensive project description, requirements, and compatibility information
[project]
name = "twat-fs"
dynamic = ["version"]  # Version is determined dynamically from VCS
description = "File system utilities for twat with support for multiple upload providers"
readme = "README.md"
requires-python = ">=3.10"  # Minimum Python version required
license = "MIT"
keywords = ["file-upload", "fal", "dropbox", "s3", "twat"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: Implementation :: CPython",
    "Programming Language :: Python :: Implementation :: PyPy",
]

# Runtime Dependencies
# -------------------
# External packages required for the project to function
dependencies = ["twat>=1.0.0", "tenacity>=8.0.0"]  # Main twat package and retry utility

# Optional dependencies for different providers and development
[project.optional-dependencies]
# Provider-specific dependencies
fal = ["fal-client>=0.5.0"]  # FAL.ai client for AI file operations

dropbox = ["dropbox>=12.00.0"]  # Dropbox SDK for cloud storage

s3 = ["boto3>=1.34.0", "botocore>=1.34.0"]  # AWS SDK for S3 storage

all = [
    "fal-client>=0.5.9",
    "dropbox>=12.0.2",
    "tenacity>8.0.0",
    "boto3>=1.36.21",
    "botocore>=1.36.21",
    "twat>=1.8.1",
]

# Development dependencies
dev = [
    "pre-commit>=4.1.0",     # Git pre-commit hooks
    "hatch>=1.14.0",         # Build tool
    "ruff>=0.9.6",           # Fast Python linter
    "mypy>=1.15.0",          # Static type checker
    "pyupgrade>=3.19.1",     # Python code upgrader
]

# Testing dependencies
test = ["pytest>=7.0.0", "pytest-cov>=4.0.0"]

# Command-line scripts
[project.scripts]
twat-fs = "twat_fs.__main__:main"

# Twat Plugin Registration
# -----------------------
# Registers this package as a plugin for the twat ecosystem
[project.entry-points."twat.plugins"]
fs = "twat_fs"

# Project Authors
# ---------------
[[project.authors]]
name = "Adam Twardoch"
email = "adam+github@twardoch.com"

# Project URLs
# ------------
# Links to project resources for documentation, issues, and source code
[project.urls]
Documentation = "https://github.com/twardoch/twat-fs#readme"
Issues = "https://github.com/twardoch/twat-fs/issues"
Source = "https://github.com/twardoch/twat-fs"

# Build System Configuration
# -------------------------
# Specifies the build system and its requirements for packaging the project
[build-system]
build-backend = "hatchling.build"
requires = ["hatchling>=1.21.0", "hatch-vcs>=0.3.0"]  # Core build backend and VCS plugin

# Coverage path mappings
[tool.coverage.paths]
twat_fs = ["src/twat_fs", "*/twat-fs/src/twat_fs"]
tests = ["tests", "*/twat-fs/tests"]

# Coverage report configuration
[tool.coverage.report]
exclude_lines = ["no cov", "if __name__ == .__main__.:", "if TYPE_CHECKING:"]

# Coverage run configuration
[tool.coverage.run]
source_pkgs = ["twat_fs", "tests"]
branch = true
parallel = true
omit = ["src/twat_fs/__about__.py"]

# VCS hook configuration for version file generation
[tool.hatch.build.hooks.vcs]
version-file = "src/twat_fs/__version__.py"

# Wheel build configuration
[tool.hatch.build.targets.wheel]
packages = ["src/twat_fs", "src/twat"]
include = ["src/twat_fs/**/*.py", "src/twat/**/*.py"]

# Default development environment configuration
[tool.hatch.envs.default]
dependencies = [
    "pytest>=8.3.4",         # Testing framework
    "pytest-cov>=6.0.0",     # Coverage reporting
    "ruff>=0.9.6",           # Fast Python linter
    "mypy>=1.15.0",          # Static type checker
]

# Python version matrix for testing
[[tool.hatch.envs.all.matrix]]
python = ["3.10", "3.11", "3.12"]

# Default environment scripts
[tool.hatch.envs.default.scripts]
test = "pytest {args:tests}"
test-cov = "pytest --cov-report=term-missing --cov-config=pyproject.toml --cov=src/twat_fs --cov=tests {args:tests}"
type-check = "mypy src/twat_fs tests"
lint = [
    "ruff check src/twat_fs tests",
    "ruff format --respect-gitignore src/twat_fs tests",
]
fix = [
    "ruff check  --fix --unsafe-fixes src/twat_fs tests",
    "ruff format --respect-gitignore src/twat_fs tests",
]

# Linting environment configuration
[tool.hatch.envs.lint]
detached = true  # Run in isolated environment
dependencies = [
    "pytest>=8.3.4",
    "pytest-cov>=6.0.0",
    "ruff>=0.9.6",
    "mypy>=1.15.0",
]

# Linting environment scripts
[tool.hatch.envs.lint.scripts]
typing = "mypy --install-types --non-interactive {args:src/twat_fs tests}"
style = ["ruff check {args:.}", "ruff format --respect-gitignore {args:.}"]
fmt = ["ruff format --respect-gitignore {args:.}", "ruff check --fix {args:.}"]
all = ["style", "typing"]

# Test environment configuration
[tool.hatch.envs.test]
dependencies = [
    "pytest>=8.3.4",
    "pytest-cov>=6.0.0",
    "boto3>=1.36.21",
    "botocore>=1.36.21",
    "dropbox>=12.0.2",
    "fal-client>=0.5.9",
]
python = "3.10"

# Test environment scripts
[tool.hatch.envs.test.scripts]
test = "python -m pytest -n auto -p no:briefcase {args:tests}"
test-cov = "python -m pytest -n auto -p no:briefcase --cov-report=term-missing --cov-config=pyproject.toml --cov=src/twat_fs --cov=tests {args:tests}"
bench = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only"
bench-save = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only --benchmark-json=benchmark/results.json"

# Version configuration using VCS (Git)
[tool.hatch.version]
source = "vcs"

# Version scheme configuration
[tool.hatch.version.raw-options]
version_scheme = "post-release"

# MyPy (type checker) configuration
[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

# Ruff (linter) configuration
[tool.ruff]
target-version = "py310"
line-length = 88

# Ruff lint rules configuration
[tool.ruff.lint]
extend-select = [
    "A",     # flake8-builtins
    "ARG",   # flake8-unused-arguments
    "B",     # flake8-bugbear
    "C",     # flake8-comprehensions
    "DTZ",   # flake8-datetimez
    "E",     # pycodestyle errors
    "EM",    # flake8-errmsg
    "F",     # pyflakes
    "FBT",   # flake8-boolean-trap
    "I",     # isort
    "ICN",   # flake8-import-conventions
    "ISC",   # flake8-implicit-str-concat
    "N",     # pep8-naming
    "PLC",   # pylint convention
    "PLE",   # pylint error
    "PLR",   # pylint refactor
    "PLW",   # pylint warning
    "Q",     # flake8-quotes
    "RUF",   # Ruff-specific rules
    "S",     # flake8-bandit
    "T",     # flake8-debugger
    "TID",   # flake8-tidy-imports
    "UP",    # pyupgrade
    "W",     # pycodestyle warnings
    "YTT",   # flake8-2020
]
ignore = ["ARG001", "E501", "I001", "RUF001", "PLR2004", "EXE003", "ISC001"]

# File-specific Ruff configurations
[tool.ruff.per-file-ignores]
"tests/*" = ["S101"]  # Allow assert in tests

# Pytest configuration
[tool.pytest.ini_options]
addopts = "-v --durations=10 -p no:briefcase"
asyncio_mode = "auto"
console_output_style = "progress"
filterwarnings = ["ignore::DeprecationWarning", "ignore::UserWarning"]
log_cli = true
log_cli_level = "INFO"
markers = [
    "benchmark: marks tests as benchmarks (select with '-m benchmark')",
    "unit: mark a test as a unit test",
    "integration: mark a test as an integration test",
    "permutation: tests for permutation functionality",
    "parameter: tests for parameter parsing",
    "prompt: tests for prompt parsing",
]
norecursedirs = [
    ".*",
    "build",
    "dist",
    "venv",
    "__pycache__",
    "*.egg-info",
    "_private",
]

python_classes = ["Test*"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
testpaths = ["tests"]

# Pytest-benchmark configuration
[tool.pytest-benchmark]
min_rounds = 100
min_time = 0.1
histogram = true
storage = "file"
save-data = true
compare = [
    "min",    # Minimum time
    "max",    # Maximum time
    "mean",   # Mean time
    "stddev", # Standard deviation
    "median", # Median time
    "iqr",    # Inter-quartile range
    "ops",    # Operations per second
    "rounds", # Number of rounds
]
